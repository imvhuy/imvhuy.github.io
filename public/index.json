[
{
	"uri": "//localhost:1313/",
	"title": "Building ETL Data Pipeline for Weather Analytics on AWS",
	"tags": [],
	"description": "",
	"content": "Building ETL Data Pipeline for Weather Analytics on AWS Overview In this comprehensive workshop, you will learn how to build a serverless ETL (Extract, Transform, Load) data pipeline for weather analytics using AWS services and real-time weather data from OpenWeatherMap API. This hands-on workshop will guide you through creating a simple, cost-effective data processing system that collects, transforms, and analyzes real weather data including current conditions, forecasts, and historical trends across multiple cities.\nWhat You\u0026rsquo;ll Build You will create a complete serverless data pipeline that:\nCollects real-time weather data from OpenWeatherMap API Processes and transforms weather data using AWS Lambda Stores structured weather data in S3 Data Lake Analyzes weather patterns using Amazon Athena Visualizes weather insights through QuickSight dashboards This workshop is designed for developers, data engineers, and cloud architects who want to gain hands-on experience with AWS data services. Prior knowledge of AWS basics and some programming experience (Python/SQL) is recommended but not required. You\u0026rsquo;ll need an OpenWeatherMap API key (free tier available).\nAWS Services You\u0026rsquo;ll Learn Data Collection:\nAWS Lambda - Serverless compute for weather data collection and processing CloudWatch Events - Scheduled execution and automation (hourly/daily) Data Storage:\nAmazon S3 - Scalable object storage for weather data lakes S3 Intelligent Tiering - Cost optimization for data storage Analytics \u0026amp; Visualization:\nAmazon Athena - Interactive query service for S3 weather data Amazon QuickSight - Business intelligence and weather visualization Monitoring \u0026amp; Management:\nAmazon CloudWatch - Monitoring, logging, and weather alerting AWS IAM - Identity and access management SNS - Weather alert notifications External Integration:\nOpenWeatherMap API - Real-time weather data source (Developer Plan) Business Use Cases This weather ETL pipeline demonstrates real-world analytics scenarios:\nClimate Analysis - Temperature, humidity, and pressure trend analysis Agriculture Intelligence - Weather conditions for crop planning and irrigation Tourism Planning - Seasonal weather patterns for travel recommendations Energy Management - Weather-based energy demand forecasting Logistics Optimization - Weather-aware supply chain and transportation Risk Management - Weather alert systems for disaster preparedness Architecture Components Data Sources - OpenWeatherMap API (current weather, forecasts, historical data) Collection Layer - Scheduled Lambda functions for multi-city weather retrieval Processing Layer - Lambda functions for data transformation and enrichment Storage Layer - S3 Data Lake with date/city partitioning Analytics Layer - Athena for SQL querying and QuickSight for weather visualization Monitoring - CloudWatch for logging, metrics, and weather alerting Expected Outcomes By the end of this workshop, you will:\nUnderstand modern serverless data pipeline architectures Master AWS Lambda for real-time weather data collection Build analytics capabilities using live weather data Implement monitoring and weather alert systems Create interactive weather dashboards with QuickSight Integrate external weather APIs into AWS data pipelines Optimize costs with minimal AWS services (under $5/month) Workshop Duration Total Time: 4-6 hours Skill Level: Beginner to Intermediate Cost: Under $5 using AWS Free Tier + OpenWeatherMap Developer Plan Prerequisites Active AWS account with administrative access OpenWeatherMap API key (Developer Plan recommended - 1M calls/month) Basic understanding of cloud computing concepts Familiarity with JSON data format and REST APIs Internet connection to access OpenWeatherMap API Optional: Basic Python or SQL knowledge Workshop Modules Introduction \u0026amp; Architecture Design Weather Data Collection with Lambda Data Processing and Transformation Setting up S3 Data Lake Analytics with Amazon Athena Weather Visualization with QuickSight Monitoring and Weather Alerts Cleanup and Next Steps "
},
{
	"uri": "//localhost:1313/2-data-collection-openweathermap/2.2-lambda-weather-collector/",
	"title": "Building Lambda Weather Collector",
	"tags": [],
	"description": "",
	"content": "Building Lambda Weather Collector In this section, we\u0026rsquo;ll create AWS Lambda functions to automatically collect weather data from OpenWeatherMap API and store it in S3. These functions will be the core of our weather data collection system.\nArchitecture Overview graph LR\rA[CloudWatch Events] --\u0026gt; B[Lambda Weather Collector]\rB --\u0026gt; C[OpenWeatherMap API]\rC --\u0026gt; D[API Response]\rD --\u0026gt; B\rB --\u0026gt; E[S3 Weather Data]\rB --\u0026gt; F[CloudWatch Logs]\rG[Parameter Store] --\u0026gt; B\rstyle B fill:#ff9900,stroke:#232f3e,stroke-width:3px\rstyle C fill:#e1f5fe\rstyle E fill:#f3e5f5 Step 1: Create IAM Role for Lambda 1.1 Create Lambda Execution Role Navigate to IAM Console\nAWS Console → IAM → Roles Click \u0026ldquo;Create role\u0026rdquo; Select Trusted Entity\nService: Lambda Click \u0026ldquo;Next\u0026rdquo; Role Configuration\nRole Name: WeatherCollectorLambdaRole Description: Execution role for weather data collection Lambda functions 1.2 Create Custom Policy Policy Name: WeatherCollectorPolicy\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;S3WeatherDataAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:PutObjectAcl\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::weather-data-lake-*\u0026#34;, \u0026#34;arn:aws:s3:::weather-data-lake-*/*\u0026#34; ] }, { \u0026#34;Sid\u0026#34;: \u0026#34;ParameterStoreAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;ssm:GetParameter\u0026#34;, \u0026#34;ssm:GetParameters\u0026#34;], \u0026#34;Resource\u0026#34;: [\u0026#34;arn:aws:ssm:*:*:parameter/weather-etl/*\u0026#34;] }, { \u0026#34;Sid\u0026#34;: \u0026#34;CloudWatchLogsAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:*:*:log-group:/aws/lambda/weather-*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;CloudWatchMetricsAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;cloudwatch:PutMetricData\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;cloudwatch:namespace\u0026#34;: \u0026#34;Weather/ETL\u0026#34; } } } ] } 1.3 Attach AWS Managed Policies Also attach this AWS managed policy:\nAWSLambdaBasicExecutionRole: arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole Step 2: Create S3 Bucket for Weather Data 2.1 Create Weather Data Bucket Navigate to S3 Console\nAWS Console → S3 → Create bucket Bucket Configuration\nBucket Name: weather-data-lake-{your-account-id} (replace with your AWS account ID) Region: us-east-1 (or your preferred region) Block Public Access: Keep all settings enabled (recommended) Bucket Structure\nweather-data-lake-123456789012/\r├── raw/\r│ ├── current-weather/\r│ │ └── year=2025/month=01/day=03/hour=10/\r│ └── forecast/\r│ └── year=2025/month=01/day=03/\r└── processed/\r├── current-weather/\r└── forecast/ Step 3: Lambda Function for Current Weather 3.1 Create Current Weather Function Navigate to Lambda Console\nAWS Console → Lambda → Create function Function Configuration\nFunction Name: weather-current-collector Runtime: Python 3.11 Architecture: x86_64 Execution Role: Use existing role → WeatherCollectorLambdaRole 3.2 Function Code File: lambda_function.py\nimport json import boto3 import requests import os from datetime import datetime, timezone from typing import Dict, List, Optional import logging # Configure logging logger = logging.getLogger() logger.setLevel(logging.INFO) # AWS clients s3_client = boto3.client(\u0026#39;s3\u0026#39;) ssm_client = boto3.client(\u0026#39;ssm\u0026#39;) cloudwatch = boto3.client(\u0026#39;cloudwatch\u0026#39;) # Configuration BUCKET_NAME = os.environ.get(\u0026#39;WEATHER_BUCKET_NAME\u0026#39;) API_KEY_PARAMETER = \u0026#39;/weather-etl/openweathermap/api-key\u0026#39; # Target cities for weather collection CITIES = [ {\u0026#39;name\u0026#39;: \u0026#39;Ho Chi Minh City\u0026#39;, \u0026#39;country\u0026#39;: \u0026#39;VN\u0026#39;, \u0026#39;lat\u0026#39;: 10.8231, \u0026#39;lon\u0026#39;: 106.6297}, {\u0026#39;name\u0026#39;: \u0026#39;Hanoi\u0026#39;, \u0026#39;country\u0026#39;: \u0026#39;VN\u0026#39;, \u0026#39;lat\u0026#39;: 21.0285, \u0026#39;lon\u0026#39;: 105.8542}, {\u0026#39;name\u0026#39;: \u0026#39;Singapore\u0026#39;, \u0026#39;country\u0026#39;: \u0026#39;SG\u0026#39;, \u0026#39;lat\u0026#39;: 1.3521, \u0026#39;lon\u0026#39;: 103.8198}, {\u0026#39;name\u0026#39;: \u0026#39;Bangkok\u0026#39;, \u0026#39;country\u0026#39;: \u0026#39;TH\u0026#39;, \u0026#39;lat\u0026#39;: 13.7563, \u0026#39;lon\u0026#39;: 100.5018}, {\u0026#39;name\u0026#39;: \u0026#39;Jakarta\u0026#39;, \u0026#39;country\u0026#39;: \u0026#39;ID\u0026#39;, \u0026#39;lat\u0026#39;: -6.2088, \u0026#39;lon\u0026#39;: 106.8456}, {\u0026#39;name\u0026#39;: \u0026#39;Kuala Lumpur\u0026#39;, \u0026#39;country\u0026#39;: \u0026#39;MY\u0026#39;, \u0026#39;lat\u0026#39;: 3.1390, \u0026#39;lon\u0026#39;: 101.6869} ] def get_api_key() -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;Retrieve OpenWeatherMap API key from Parameter Store.\u0026#34;\u0026#34;\u0026#34; try: response = ssm_client.get_parameter( Name=API_KEY_PARAMETER, WithDecryption=True ) return response[\u0026#39;Parameter\u0026#39;][\u0026#39;Value\u0026#39;] except Exception as e: logger.error(f\u0026#34;Failed to retrieve API key: {e}\u0026#34;) raise def fetch_current_weather(city: Dict, api_key: str) -\u0026gt; Optional[Dict]: \u0026#34;\u0026#34;\u0026#34;Fetch current weather data for a city.\u0026#34;\u0026#34;\u0026#34; base_url = \u0026#34;https://api.openweathermap.org/data/2.5/weather\u0026#34; params = { \u0026#39;lat\u0026#39;: city[\u0026#39;lat\u0026#39;], \u0026#39;lon\u0026#39;: city[\u0026#39;lon\u0026#39;], \u0026#39;appid\u0026#39;: api_key, \u0026#39;units\u0026#39;: \u0026#39;metric\u0026#39; } try: response = requests.get(base_url, params=params, timeout=10) response.raise_for_status() weather_data = response.json() # Add metadata weather_data[\u0026#39;collection_metadata\u0026#39;] = { \u0026#39;collection_time\u0026#39;: datetime.now(timezone.utc).isoformat(), \u0026#39;data_source\u0026#39;: \u0026#39;openweathermap\u0026#39;, \u0026#39;api_version\u0026#39;: \u0026#39;2.5\u0026#39;, \u0026#39;collection_type\u0026#39;: \u0026#39;current_weather\u0026#39; } return weather_data except requests.exceptions.RequestException as e: logger.error(f\u0026#34;Failed to fetch weather for {city[\u0026#39;name\u0026#39;]}: {e}\u0026#34;) return None def store_weather_data(weather_data: Dict, city: Dict) -\u0026gt; bool: \u0026#34;\u0026#34;\u0026#34;Store weather data in S3 with partitioned structure.\u0026#34;\u0026#34;\u0026#34; try: now = datetime.now(timezone.utc) # Create S3 key with partitioning s3_key = ( f\u0026#34;raw/current-weather/\u0026#34; f\u0026#34;year={now.year}/\u0026#34; f\u0026#34;month={now.month:02d}/\u0026#34; f\u0026#34;day={now.day:02d}/\u0026#34; f\u0026#34;hour={now.hour:02d}/\u0026#34; f\u0026#34;{city[\u0026#39;name\u0026#39;].lower().replace(\u0026#39; \u0026#39;, \u0026#39;_\u0026#39;)}_{now.strftime(\u0026#39;%Y%m%d_%H%M%S\u0026#39;)}.json\u0026#34; ) # Upload to S3 s3_client.put_object( Bucket=BUCKET_NAME, Key=s3_key, Body=json.dumps(weather_data, indent=2), ContentType=\u0026#39;application/json\u0026#39;, Metadata={ \u0026#39;city\u0026#39;: city[\u0026#39;name\u0026#39;], \u0026#39;country\u0026#39;: city[\u0026#39;country\u0026#39;], \u0026#39;collection_time\u0026#39;: now.isoformat(), \u0026#39;data_type\u0026#39;: \u0026#39;current_weather\u0026#39; } ) logger.info(f\u0026#34;Stored weather data for {city[\u0026#39;name\u0026#39;]} at s3://{BUCKET_NAME}/{s3_key}\u0026#34;) return True except Exception as e: logger.error(f\u0026#34;Failed to store weather data for {city[\u0026#39;name\u0026#39;]}: {e}\u0026#34;) return False def send_custom_metrics(successful_collections: int, failed_collections: int): \u0026#34;\u0026#34;\u0026#34;Send custom metrics to CloudWatch.\u0026#34;\u0026#34;\u0026#34; try: cloudwatch.put_metric_data( Namespace=\u0026#39;Weather/ETL\u0026#39;, MetricData=[ { \u0026#39;MetricName\u0026#39;: \u0026#39;SuccessfulCollections\u0026#39;, \u0026#39;Value\u0026#39;: successful_collections, \u0026#39;Unit\u0026#39;: \u0026#39;Count\u0026#39;, \u0026#39;Dimensions\u0026#39;: [ { \u0026#39;Name\u0026#39;: \u0026#39;DataType\u0026#39;, \u0026#39;Value\u0026#39;: \u0026#39;CurrentWeather\u0026#39; } ] }, { \u0026#39;MetricName\u0026#39;: \u0026#39;FailedCollections\u0026#39;, \u0026#39;Value\u0026#39;: failed_collections, \u0026#39;Unit\u0026#39;: \u0026#39;Count\u0026#39;, \u0026#39;Dimensions\u0026#39;: [ { \u0026#39;Name\u0026#39;: \u0026#39;DataType\u0026#39;, \u0026#39;Value\u0026#39;: \u0026#39;CurrentWeather\u0026#39; } ] } ] ) except Exception as e: logger.error(f\u0026#34;Failed to send metrics: {e}\u0026#34;) def lambda_handler(event, context): \u0026#34;\u0026#34;\u0026#34;Main Lambda handler for current weather collection.\u0026#34;\u0026#34;\u0026#34; logger.info(\u0026#34;Starting current weather collection\u0026#34;) try: # Get API key api_key = get_api_key() successful_collections = 0 failed_collections = 0 results = [] # Collect weather data for each city for city in CITIES: logger.info(f\u0026#34;Collecting weather data for {city[\u0026#39;name\u0026#39;]}\u0026#34;) # Fetch weather data weather_data = fetch_current_weather(city, api_key) if weather_data: # Store in S3 if store_weather_data(weather_data, city): successful_collections += 1 results.append({ \u0026#39;city\u0026#39;: city[\u0026#39;name\u0026#39;], \u0026#39;status\u0026#39;: \u0026#39;success\u0026#39;, \u0026#39;temperature\u0026#39;: weather_data.get(\u0026#39;main\u0026#39;, {}).get(\u0026#39;temp\u0026#39;), \u0026#39;weather\u0026#39;: weather_data.get(\u0026#39;weather\u0026#39;, [{}])[0].get(\u0026#39;description\u0026#39;) }) else: failed_collections += 1 results.append({ \u0026#39;city\u0026#39;: city[\u0026#39;name\u0026#39;], \u0026#39;status\u0026#39;: \u0026#39;storage_failed\u0026#39; }) else: failed_collections += 1 results.append({ \u0026#39;city\u0026#39;: city[\u0026#39;name\u0026#39;], \u0026#39;status\u0026#39;: \u0026#39;api_failed\u0026#39; }) # Send metrics to CloudWatch send_custom_metrics(successful_collections, failed_collections) # Return results return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps({ \u0026#39;message\u0026#39;: \u0026#39;Weather collection completed\u0026#39;, \u0026#39;successful_collections\u0026#39;: successful_collections, \u0026#39;failed_collections\u0026#39;: failed_collections, \u0026#39;results\u0026#39;: results }) } except Exception as e: logger.error(f\u0026#34;Lambda execution failed: {e}\u0026#34;) return { \u0026#39;statusCode\u0026#39;: 500, \u0026#39;body\u0026#39;: json.dumps({ \u0026#39;error\u0026#39;: str(e) }) } 3.3 Environment Variables Set these environment variables for the Lambda function:\nVariable Value WEATHER_BUCKET_NAME weather-data-lake-{your-account-id} 3.4 Function Configuration Timeout: 5 minutes Memory: 256 MB Dead Letter Queue: Create SQS queue weather-collection-dlq Step 4: Lambda Function for Weather Forecasts 4.1 Create Forecast Function Function Name: weather-forecast-collector Runtime: Python 3.11 Execution Role: WeatherCollectorLambdaRole 4.2 Forecast Function Code File: lambda_function.py\nimport json import boto3 import requests import os from datetime import datetime, timezone from typing import Dict, List, Optional import logging # Configure logging logger = logging.getLogger() logger.setLevel(logging.INFO) # AWS clients s3_client = boto3.client(\u0026#39;s3\u0026#39;) ssm_client = boto3.client(\u0026#39;ssm\u0026#39;) cloudwatch = boto3.client(\u0026#39;cloudwatch\u0026#39;) # Configuration BUCKET_NAME = os.environ.get(\u0026#39;WEATHER_BUCKET_NAME\u0026#39;) API_KEY_PARAMETER = \u0026#39;/weather-etl/openweathermap/api-key\u0026#39; # Target cities (same as current weather) CITIES = [ {\u0026#39;name\u0026#39;: \u0026#39;Ho Chi Minh City\u0026#39;, \u0026#39;country\u0026#39;: \u0026#39;VN\u0026#39;, \u0026#39;lat\u0026#39;: 10.8231, \u0026#39;lon\u0026#39;: 106.6297}, {\u0026#39;name\u0026#39;: \u0026#39;Hanoi\u0026#39;, \u0026#39;country\u0026#39;: \u0026#39;VN\u0026#39;, \u0026#39;lat\u0026#39;: 21.0285, \u0026#39;lon\u0026#39;: 105.8542}, {\u0026#39;name\u0026#39;: \u0026#39;Singapore\u0026#39;, \u0026#39;country\u0026#39;: \u0026#39;SG\u0026#39;, \u0026#39;lat\u0026#39;: 1.3521, \u0026#39;lon\u0026#39;: 103.8198}, {\u0026#39;name\u0026#39;: \u0026#39;Bangkok\u0026#39;, \u0026#39;country\u0026#39;: \u0026#39;TH\u0026#39;, \u0026#39;lat\u0026#39;: 13.7563, \u0026#39;lon\u0026#39;: 100.5018}, {\u0026#39;name\u0026#39;: \u0026#39;Jakarta\u0026#39;, \u0026#39;country\u0026#39;: \u0026#39;ID\u0026#39;, \u0026#39;lat\u0026#39;: -6.2088, \u0026#39;lon\u0026#39;: 106.8456}, {\u0026#39;name\u0026#39;: \u0026#39;Kuala Lumpur\u0026#39;, \u0026#39;country\u0026#39;: \u0026#39;MY\u0026#39;, \u0026#39;lat\u0026#39;: 3.1390, \u0026#39;lon\u0026#39;: 101.6869} ] def get_api_key() -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;Retrieve OpenWeatherMap API key from Parameter Store.\u0026#34;\u0026#34;\u0026#34; try: response = ssm_client.get_parameter( Name=API_KEY_PARAMETER, WithDecryption=True ) return response[\u0026#39;Parameter\u0026#39;][\u0026#39;Value\u0026#39;] except Exception as e: logger.error(f\u0026#34;Failed to retrieve API key: {e}\u0026#34;) raise def fetch_weather_forecast(city: Dict, api_key: str) -\u0026gt; Optional[Dict]: \u0026#34;\u0026#34;\u0026#34;Fetch 5-day weather forecast for a city.\u0026#34;\u0026#34;\u0026#34; base_url = \u0026#34;https://api.openweathermap.org/data/2.5/forecast\u0026#34; params = { \u0026#39;lat\u0026#39;: city[\u0026#39;lat\u0026#39;], \u0026#39;lon\u0026#39;: city[\u0026#39;lon\u0026#39;], \u0026#39;appid\u0026#39;: api_key, \u0026#39;units\u0026#39;: \u0026#39;metric\u0026#39; } try: response = requests.get(base_url, params=params, timeout=15) response.raise_for_status() forecast_data = response.json() # Add metadata forecast_data[\u0026#39;collection_metadata\u0026#39;] = { \u0026#39;collection_time\u0026#39;: datetime.now(timezone.utc).isoformat(), \u0026#39;data_source\u0026#39;: \u0026#39;openweathermap\u0026#39;, \u0026#39;api_version\u0026#39;: \u0026#39;2.5\u0026#39;, \u0026#39;collection_type\u0026#39;: \u0026#39;forecast\u0026#39;, \u0026#39;forecast_periods\u0026#39;: len(forecast_data.get(\u0026#39;list\u0026#39;, [])) } return forecast_data except requests.exceptions.RequestException as e: logger.error(f\u0026#34;Failed to fetch forecast for {city[\u0026#39;name\u0026#39;]}: {e}\u0026#34;) return None def store_forecast_data(forecast_data: Dict, city: Dict) -\u0026gt; bool: \u0026#34;\u0026#34;\u0026#34;Store forecast data in S3 with partitioned structure.\u0026#34;\u0026#34;\u0026#34; try: now = datetime.now(timezone.utc) # Create S3 key with partitioning s3_key = ( f\u0026#34;raw/forecast/\u0026#34; f\u0026#34;year={now.year}/\u0026#34; f\u0026#34;month={now.month:02d}/\u0026#34; f\u0026#34;day={now.day:02d}/\u0026#34; f\u0026#34;{city[\u0026#39;name\u0026#39;].lower().replace(\u0026#39; \u0026#39;, \u0026#39;_\u0026#39;)}_{now.strftime(\u0026#39;%Y%m%d_%H%M%S\u0026#39;)}.json\u0026#34; ) # Upload to S3 s3_client.put_object( Bucket=BUCKET_NAME, Key=s3_key, Body=json.dumps(forecast_data, indent=2), ContentType=\u0026#39;application/json\u0026#39;, Metadata={ \u0026#39;city\u0026#39;: city[\u0026#39;name\u0026#39;], \u0026#39;country\u0026#39;: city[\u0026#39;country\u0026#39;], \u0026#39;collection_time\u0026#39;: now.isoformat(), \u0026#39;data_type\u0026#39;: \u0026#39;forecast\u0026#39;, \u0026#39;forecast_periods\u0026#39;: str(len(forecast_data.get(\u0026#39;list\u0026#39;, []))) } ) logger.info(f\u0026#34;Stored forecast data for {city[\u0026#39;name\u0026#39;]} at s3://{BUCKET_NAME}/{s3_key}\u0026#34;) return True except Exception as e: logger.error(f\u0026#34;Failed to store forecast data for {city[\u0026#39;name\u0026#39;]}: {e}\u0026#34;) return False def lambda_handler(event, context): \u0026#34;\u0026#34;\u0026#34;Main Lambda handler for weather forecast collection.\u0026#34;\u0026#34;\u0026#34; logger.info(\u0026#34;Starting weather forecast collection\u0026#34;) try: # Get API key api_key = get_api_key() successful_collections = 0 failed_collections = 0 results = [] # Collect forecast data for each city for city in CITIES: logger.info(f\u0026#34;Collecting forecast data for {city[\u0026#39;name\u0026#39;]}\u0026#34;) # Fetch forecast data forecast_data = fetch_weather_forecast(city, api_key) if forecast_data: # Store in S3 if store_forecast_data(forecast_data, city): successful_collections += 1 forecast_count = len(forecast_data.get(\u0026#39;list\u0026#39;, [])) results.append({ \u0026#39;city\u0026#39;: city[\u0026#39;name\u0026#39;], \u0026#39;status\u0026#39;: \u0026#39;success\u0026#39;, \u0026#39;forecast_periods\u0026#39;: forecast_count }) else: failed_collections += 1 results.append({ \u0026#39;city\u0026#39;: city[\u0026#39;name\u0026#39;], \u0026#39;status\u0026#39;: \u0026#39;storage_failed\u0026#39; }) else: failed_collections += 1 results.append({ \u0026#39;city\u0026#39;: city[\u0026#39;name\u0026#39;], \u0026#39;status\u0026#39;: \u0026#39;api_failed\u0026#39; }) # Send metrics to CloudWatch cloudwatch.put_metric_data( Namespace=\u0026#39;Weather/ETL\u0026#39;, MetricData=[ { \u0026#39;MetricName\u0026#39;: \u0026#39;SuccessfulCollections\u0026#39;, \u0026#39;Value\u0026#39;: successful_collections, \u0026#39;Unit\u0026#39;: \u0026#39;Count\u0026#39;, \u0026#39;Dimensions\u0026#39;: [ { \u0026#39;Name\u0026#39;: \u0026#39;DataType\u0026#39;, \u0026#39;Value\u0026#39;: \u0026#39;Forecast\u0026#39; } ] } ] ) # Return results return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps({ \u0026#39;message\u0026#39;: \u0026#39;Forecast collection completed\u0026#39;, \u0026#39;successful_collections\u0026#39;: successful_collections, \u0026#39;failed_collections\u0026#39;: failed_collections, \u0026#39;results\u0026#39;: results }) } except Exception as e: logger.error(f\u0026#34;Lambda execution failed: {e}\u0026#34;) return { \u0026#39;statusCode\u0026#39;: 500, \u0026#39;body\u0026#39;: json.dumps({ \u0026#39;error\u0026#39;: str(e) }) } Step 5: Test Lambda Functions 5.1 Test Current Weather Function Create Test Event\n{ \u0026#34;test\u0026#34;: true, \u0026#34;cities\u0026#34;: [\u0026#34;Ho Chi Minh City\u0026#34;] } Run Test\nClick \u0026ldquo;Test\u0026rdquo; in Lambda console Check execution logs Verify S3 object creation 5.2 Expected Test Results Successful Response:\n{ \u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: \u0026#34;{\\\u0026#34;message\\\u0026#34;: \\\u0026#34;Weather collection completed\\\u0026#34;, \\\u0026#34;successful_collections\\\u0026#34;: 6, \\\u0026#34;failed_collections\\\u0026#34;: 0, \\\u0026#34;results\\\u0026#34;: [...]}\u0026#34; } S3 Structure After Test:\nweather-data-lake-123456789012/\r└── raw/\r├── current-weather/\r│ └── year=2025/month=01/day=03/hour=14/\r│ ├── ho_chi_minh_city_20250103_140532.json\r│ ├── hanoi_20250103_140534.json\r│ └── ...\r└── forecast/\r└── year=2025/month=01/day=03/\r├── ho_chi_minh_city_20250103_140612.json\r└── ... Step 6: Monitor Function Performance 6.1 CloudWatch Metrics Key metrics to monitor:\nDuration: Function execution time Errors: Failed executions Throttles: Concurrent execution limits Custom Metrics: Successful/failed collections 6.2 Set Up Alarms High Error Rate Alarm:\n{ \u0026#34;AlarmName\u0026#34;: \u0026#34;WeatherCollector-HighErrorRate\u0026#34;, \u0026#34;MetricName\u0026#34;: \u0026#34;Errors\u0026#34;, \u0026#34;Namespace\u0026#34;: \u0026#34;AWS/Lambda\u0026#34;, \u0026#34;Statistic\u0026#34;: \u0026#34;Sum\u0026#34;, \u0026#34;Period\u0026#34;: 300, \u0026#34;EvaluationPeriods\u0026#34;: 2, \u0026#34;Threshold\u0026#34;: 3, \u0026#34;ComparisonOperator\u0026#34;: \u0026#34;GreaterThanThreshold\u0026#34; } Next Steps Excellent! You now have Lambda functions that can collect weather data from OpenWeatherMap API. In the next section, we\u0026rsquo;ll set up automated scheduling using CloudWatch Events to run these functions on a regular schedule.\nWhat You\u0026rsquo;ve Built:\nLambda execution role with proper permissions S3 bucket with partitioned structure Current weather collection function Weather forecast collection function Error handling and monitoring Performance Tips:\nMonitor API response times and adjust timeout accordingly Use CloudWatch Logs Insights to analyze function performance Consider increasing memory for faster execution Set up Dead Letter Queues for failed executions "
},
{
	"uri": "//localhost:1313/2-data-collection-openweathermap/2.1-openweathermap-setup/",
	"title": "OpenWeatherMap API Setup",
	"tags": [],
	"description": "",
	"content": "OpenWeatherMap API Setup In this simplified section, we\u0026rsquo;ll quickly set up an OpenWeatherMap API account to collect weather data for our pipeline.\nStep 1: Sign Up for OpenWeatherMap Create an account Go to https://openweathermap.org and click \u0026ldquo;Sign Up\u0026rdquo; Complete registration with your email Verify your email and log in Step 2: Get Your API Key Access API Keys After logging in, go to \u0026ldquo;API keys\u0026rdquo; section Note your default API key or create a new one named \u0026ldquo;weather-data-collection\u0026rdquo; The free plan includes 1,000 API calls per day and 60 calls per minute - more than enough for our workshop.\nStep 3: Test Your API Key Test your API key with one of these methods:\nBrowser method:\nhttps://api.openweathermap.org/data/2.5/weather?q=London\u0026amp;appid=YOUR_API_KEY cURL method:\ncurl \u0026#34;https://api.openweathermap.org/data/2.5/weather?q=London\u0026amp;appid=YOUR_API_KEY\u0026#34; You should see a JSON response with London weather data.\nStep 4: Store Your API Key Securely Using AWS Systems Manager Open AWS Management Console Go to Systems Manager → Parameter Store Click \u0026ldquo;Create parameter\u0026rdquo; Set these values: Name: /weather-etl/openweathermap/api-key Type: SecureString Value: Your API key Click \u0026ldquo;Create parameter\u0026rdquo; Key API Endpoints We\u0026rsquo;ll Use # Current Weather https://api.openweathermap.org/data/2.5/weather?q={city}\u0026amp;appid={API key} # 5-Day Forecast (3-hour intervals) https://api.openweathermap.org/data/2.5/forecast?q={city}\u0026amp;appid={API key} Next Steps That\u0026rsquo;s it! You now have a working OpenWeatherMap API key securely stored in Parameter Store. In the next section, we\u0026rsquo;ll create a Lambda function to collect weather data.\nCompleted:\nCreated OpenWeatherMap account Obtained API key Stored API key in AWS Parameter Store "
},
{
	"uri": "//localhost:1313/2-data-collection-openweathermap/2.3-automated-scheduling/",
	"title": "Automated Scheduling with CloudWatch Events",
	"tags": [],
	"description": "",
	"content": "Automated Scheduling with CloudWatch Events In this section, we\u0026rsquo;ll set up automated scheduling for our weather data collection using Amazon CloudWatch Events (now called Amazon EventBridge). This will ensure our Lambda functions run on a regular schedule to collect weather data consistently.\nArchitecture Overview graph TD\rA[CloudWatch Events Rules] --\u0026gt; B[Current Weather Schedule\u0026lt;br/\u0026gt;Every Hour]\rA --\u0026gt; C[Forecast Schedule\u0026lt;br/\u0026gt;Every 6 Hours]\rB --\u0026gt; D[Lambda: weather-current-collector]\rC --\u0026gt; E[Lambda: weather-forecast-collector]\rD --\u0026gt; F[S3: Current Weather Data]\rE --\u0026gt; G[S3: Forecast Data]\rH[CloudWatch Alarms] --\u0026gt; I[SNS Notifications]\rstyle A fill:#e8f5e8\rstyle D fill:#ff9900,stroke:#232f3e,stroke-width:3px\rstyle E fill:#ff9900,stroke:#232f3e,stroke-width:3px Step 1: Create CloudWatch Events Rules 1.1 Schedule for Current Weather Collection Navigate to CloudWatch Console\nAWS Console → CloudWatch → Events → Rules Click \u0026ldquo;Create rule\u0026rdquo; Event Source Configuration\nEvent Source: Schedule Schedule Expression: rate(1 hour) Description: \u0026ldquo;Trigger current weather collection every hour\u0026rdquo; Target Configuration\nTarget: Lambda function Function: weather-current-collector Configure input: Constant (JSON text) Input JSON:\n{ \u0026#34;source\u0026#34;: \u0026#34;cloudwatch-events\u0026#34;, \u0026#34;detail-type\u0026#34;: \u0026#34;Scheduled Event\u0026#34;, \u0026#34;detail\u0026#34;: { \u0026#34;collection_type\u0026#34;: \u0026#34;current_weather\u0026#34;, \u0026#34;scheduled_time\u0026#34;: \u0026#34;hourly\u0026#34; } } Rule Details Name: weather-current-hourly Description: \u0026ldquo;Hourly collection of current weather data for 6 cities\u0026rdquo; State: Enabled 1.2 Schedule for Weather Forecast Collection Create Second Rule\nEvent Source: Schedule Schedule Expression: rate(6 hours) Description: \u0026ldquo;Trigger weather forecast collection every 6 hours\u0026rdquo; Target Configuration\nTarget: Lambda function Function: weather-forecast-collector Input JSON:\n{ \u0026#34;source\u0026#34;: \u0026#34;cloudwatch-events\u0026#34;, \u0026#34;detail-type\u0026#34;: \u0026#34;Scheduled Event\u0026#34;, \u0026#34;detail\u0026#34;: { \u0026#34;collection_type\u0026#34;: \u0026#34;forecast\u0026#34;, \u0026#34;scheduled_time\u0026#34;: \u0026#34;every_6_hours\u0026#34; } } Rule Details Name: weather-forecast-6hourly Description: \u0026ldquo;6-hourly collection of weather forecast data\u0026rdquo; State: Enabled Step 2: Advanced Scheduling Options 2.1 Using Cron Expressions For more precise scheduling, you can use cron expressions:\nCurrent Weather at specific times:\ncron(0 0,6,12,18 * * ? *) This runs at 00:00, 06:00, 12:00, and 18:00 UTC daily.\nForecast at 06:00 and 18:00 UTC:\ncron(0 6,18 * * ? *) Hourly during business hours (UTC+7):\ncron(0 1-14 * * ? *) This runs hourly from 01:00 to 14:00 UTC (08:00 to 21:00 Vietnam time).\n2.2 Different Schedules for Different Cities Create city-specific rules:\nRule for Asian Cities (UTC+7/+8):\n{ \u0026#34;source\u0026#34;: \u0026#34;cloudwatch-events\u0026#34;, \u0026#34;detail\u0026#34;: { \u0026#34;cities\u0026#34;: [\u0026#34;Ho Chi Minh City\u0026#34;, \u0026#34;Hanoi\u0026#34;, \u0026#34;Singapore\u0026#34;, \u0026#34;Bangkok\u0026#34;], \u0026#34;timezone\u0026#34;: \u0026#34;Asia/Ho_Chi_Minh\u0026#34; } } Schedule: cron(0 1,7,13,19 * * ? *) (Peak hours in Asia)\nStep 3: Create SNS Topic for Notifications 3.1 Set Up SNS Topic Navigate to SNS Console\nAWS Console → SNS → Topics Click \u0026ldquo;Create topic\u0026rdquo; Topic Configuration\nType: Standard Name: weather-collection-alerts Display Name: \u0026ldquo;Weather Collection Alerts\u0026rdquo; Create Subscription\nProtocol: Email Endpoint: Your email address Confirm subscription via email 3.2 SNS Topic Policy { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudWatchAlarmsToPublish\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudwatch.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;SNS:Publish\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sns:us-east-1:123456789012:weather-collection-alerts\u0026#34; } ] } Step 4: Set Up Monitoring and Alarms 4.1 Lambda Function Alarms Error Rate Alarm:\n{ \u0026#34;AlarmName\u0026#34;: \u0026#34;WeatherCollection-HighErrorRate\u0026#34;, \u0026#34;AlarmDescription\u0026#34;: \u0026#34;High error rate in weather collection functions\u0026#34;, \u0026#34;MetricName\u0026#34;: \u0026#34;Errors\u0026#34;, \u0026#34;Namespace\u0026#34;: \u0026#34;AWS/Lambda\u0026#34;, \u0026#34;Statistic\u0026#34;: \u0026#34;Sum\u0026#34;, \u0026#34;Period\u0026#34;: 3600, \u0026#34;EvaluationPeriods\u0026#34;: 1, \u0026#34;Threshold\u0026#34;: 2, \u0026#34;ComparisonOperator\u0026#34;: \u0026#34;GreaterThanOrEqualToThreshold\u0026#34;, \u0026#34;Dimensions\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;FunctionName\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;weather-current-collector\u0026#34; } ], \u0026#34;AlarmActions\u0026#34;: [ \u0026#34;arn:aws:sns:us-east-1:123456789012:weather-collection-alerts\u0026#34; ] } Duration Alarm:\n{ \u0026#34;AlarmName\u0026#34;: \u0026#34;WeatherCollection-LongDuration\u0026#34;, \u0026#34;AlarmDescription\u0026#34;: \u0026#34;Weather collection taking too long\u0026#34;, \u0026#34;MetricName\u0026#34;: \u0026#34;Duration\u0026#34;, \u0026#34;Namespace\u0026#34;: \u0026#34;AWS/Lambda\u0026#34;, \u0026#34;Statistic\u0026#34;: \u0026#34;Average\u0026#34;, \u0026#34;Period\u0026#34;: 3600, \u0026#34;EvaluationPeriods\u0026#34;: 2, \u0026#34;Threshold\u0026#34;: 30000, \u0026#34;ComparisonOperator\u0026#34;: \u0026#34;GreaterThanThreshold\u0026#34;, \u0026#34;Unit\u0026#34;: \u0026#34;Milliseconds\u0026#34; } 4.2 Custom Metrics Alarms Failed Collections Alarm:\n{ \u0026#34;AlarmName\u0026#34;: \u0026#34;WeatherCollection-FailedCollections\u0026#34;, \u0026#34;AlarmDescription\u0026#34;: \u0026#34;Too many failed weather data collections\u0026#34;, \u0026#34;MetricName\u0026#34;: \u0026#34;FailedCollections\u0026#34;, \u0026#34;Namespace\u0026#34;: \u0026#34;Weather/ETL\u0026#34;, \u0026#34;Statistic\u0026#34;: \u0026#34;Sum\u0026#34;, \u0026#34;Period\u0026#34;: 3600, \u0026#34;EvaluationPeriods\u0026#34;: 1, \u0026#34;Threshold\u0026#34;: 3, \u0026#34;ComparisonOperator\u0026#34;: \u0026#34;GreaterThanThreshold\u0026#34;, \u0026#34;AlarmActions\u0026#34;: [ \u0026#34;arn:aws:sns:us-east-1:123456789012:weather-collection-alerts\u0026#34; ] } 4.3 API Usage Monitoring Create a custom metric to track OpenWeatherMap API usage:\nLambda Function Addition:\ndef send_api_usage_metrics(api_calls_made: int): \u0026#34;\u0026#34;\u0026#34;Track API usage to monitor limits.\u0026#34;\u0026#34;\u0026#34; try: cloudwatch.put_metric_data( Namespace=\u0026#39;Weather/APIUsage\u0026#39;, MetricData=[ { \u0026#39;MetricName\u0026#39;: \u0026#39;APICalls\u0026#39;, \u0026#39;Value\u0026#39;: api_calls_made, \u0026#39;Unit\u0026#39;: \u0026#39;Count\u0026#39;, \u0026#39;Dimensions\u0026#39;: [ { \u0026#39;Name\u0026#39;: \u0026#39;Provider\u0026#39;, \u0026#39;Value\u0026#39;: \u0026#39;OpenWeatherMap\u0026#39; } ] } ] ) except Exception as e: logger.error(f\u0026#34;Failed to send API usage metrics: {e}\u0026#34;) API Limit Alarm:\n{ \u0026#34;AlarmName\u0026#34;: \u0026#34;OpenWeatherMap-APILimitApproaching\u0026#34;, \u0026#34;AlarmDescription\u0026#34;: \u0026#34;Approaching OpenWeatherMap daily API limit\u0026#34;, \u0026#34;MetricName\u0026#34;: \u0026#34;APICalls\u0026#34;, \u0026#34;Namespace\u0026#34;: \u0026#34;Weather/APIUsage\u0026#34;, \u0026#34;Statistic\u0026#34;: \u0026#34;Sum\u0026#34;, \u0026#34;Period\u0026#34;: 86400, \u0026#34;EvaluationPeriods\u0026#34;: 1, \u0026#34;Threshold\u0026#34;: 800, \u0026#34;ComparisonOperator\u0026#34;: \u0026#34;GreaterThanThreshold\u0026#34; } Step 5: Create CloudWatch Dashboard 5.1 Weather Collection Dashboard Navigate to CloudWatch Dashboards\nAWS Console → CloudWatch → Dashboards Click \u0026ldquo;Create dashboard\u0026rdquo; Dashboard Configuration\nName: Weather-ETL-Dashboard Add Widgets\nWidget 1: Lambda Invocations\n{ \u0026#34;type\u0026#34;: \u0026#34;metric\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;metrics\u0026#34;: [ [ \u0026#34;AWS/Lambda\u0026#34;, \u0026#34;Invocations\u0026#34;, \u0026#34;FunctionName\u0026#34;, \u0026#34;weather-current-collector\u0026#34; ], [\u0026#34;.\u0026#34;, \u0026#34;.\u0026#34;, \u0026#34;.\u0026#34;, \u0026#34;weather-forecast-collector\u0026#34;] ], \u0026#34;period\u0026#34;: 3600, \u0026#34;stat\u0026#34;: \u0026#34;Sum\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;us-east-1\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Lambda Invocations\u0026#34; } } Widget 2: Collection Success Rate\n{ \u0026#34;type\u0026#34;: \u0026#34;metric\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;metrics\u0026#34;: [ [\u0026#34;Weather/ETL\u0026#34;, \u0026#34;SuccessfulCollections\u0026#34;, \u0026#34;DataType\u0026#34;, \u0026#34;CurrentWeather\u0026#34;], [\u0026#34;.\u0026#34;, \u0026#34;FailedCollections\u0026#34;, \u0026#34;.\u0026#34;, \u0026#34;.\u0026#34;], [\u0026#34;.\u0026#34;, \u0026#34;SuccessfulCollections\u0026#34;, \u0026#34;.\u0026#34;, \u0026#34;Forecast\u0026#34;], [\u0026#34;.\u0026#34;, \u0026#34;FailedCollections\u0026#34;, \u0026#34;.\u0026#34;, \u0026#34;.\u0026#34;] ], \u0026#34;period\u0026#34;: 3600, \u0026#34;stat\u0026#34;: \u0026#34;Sum\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;us-east-1\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Collection Success vs Failures\u0026#34; } } Widget 3: API Usage\n{ \u0026#34;type\u0026#34;: \u0026#34;metric\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;metrics\u0026#34;: [[\u0026#34;Weather/APIUsage\u0026#34;, \u0026#34;APICalls\u0026#34;, \u0026#34;Provider\u0026#34;, \u0026#34;OpenWeatherMap\u0026#34;]], \u0026#34;period\u0026#34;: 86400, \u0026#34;stat\u0026#34;: \u0026#34;Sum\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;us-east-1\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Daily API Usage\u0026#34; } } Step 6: Error Handling and Recovery 6.1 Dead Letter Queues Create DLQ for Current Weather\nAWS Console → SQS → Create queue Name: weather-current-collector-dlq Type: Standard queue Configure Lambda DLQ\nLambda function → Configuration → Asynchronous invocation Dead letter queue: weather-current-collector-dlq Maximum age of event: 6 hours Retry attempts: 2 6.2 DLQ Processing Function Create DLQ processor: weather-dlq-processor\nimport json import boto3 import logging from datetime import datetime logger = logging.getLogger() logger.setLevel(logging.INFO) def lambda_handler(event, context): \u0026#34;\u0026#34;\u0026#34;Process messages from dead letter queue.\u0026#34;\u0026#34;\u0026#34; for record in event[\u0026#39;Records\u0026#39;]: try: # Parse the failed message message_body = json.loads(record[\u0026#39;body\u0026#39;]) logger.error(f\u0026#34;Processing failed message: {message_body}\u0026#34;) # You can implement retry logic here # Or send to another system for manual review # Send alert to SNS sns = boto3.client(\u0026#39;sns\u0026#39;) sns.publish( TopicArn=\u0026#39;arn:aws:sns:us-east-1:123456789012:weather-collection-alerts\u0026#39;, Message=f\u0026#34;Weather collection failed permanently: {json.dumps(message_body)}\u0026#34;, Subject=\u0026#34;Weather Collection - Dead Letter Queue Alert\u0026#34; ) except Exception as e: logger.error(f\u0026#34;Failed to process DLQ message: {e}\u0026#34;) return {\u0026#39;statusCode\u0026#39;: 200} Step 7: Cost Optimization 7.1 Optimize Scheduling Peak Hours Only (for development):\ncron(0 6,12,18 * * ? *) Reduces from 24 to 3 collections per day.\nBusiness Hours Only:\ncron(0 8-17 * * 1-5 *) Collects only during weekday business hours.\n7.2 Batch Collection Modify Lambda to collect multiple cities in fewer API calls:\ndef collect_weather_batch(cities_batch: List[Dict], api_key: str): \u0026#34;\u0026#34;\u0026#34;Collect weather for multiple cities in one function call.\u0026#34;\u0026#34;\u0026#34; results = [] for city in cities_batch: weather_data = fetch_current_weather(city, api_key) if weather_data: store_weather_data(weather_data, city) results.append({\u0026#39;city\u0026#39;: city[\u0026#39;name\u0026#39;], \u0026#39;status\u0026#39;: \u0026#39;success\u0026#39;}) # Small delay to respect rate limits time.sleep(0.1) return results 7.3 Smart Scheduling Weather-Dependent Scheduling:\ndef should_collect_forecast(current_weather: Dict) -\u0026gt; bool: \u0026#34;\u0026#34;\u0026#34;Decide if forecast collection is needed based on current conditions.\u0026#34;\u0026#34;\u0026#34; # Skip forecast if weather is stable weather_main = current_weather.get(\u0026#39;weather\u0026#39;, [{}])[0].get(\u0026#39;main\u0026#39;, \u0026#39;\u0026#39;) if weather_main in [\u0026#39;Clear\u0026#39;, \u0026#39;Clouds\u0026#39;] and \\ current_weather.get(\u0026#39;wind\u0026#39;, {}).get(\u0026#39;speed\u0026#39;, 0) \u0026lt; 5: return False # Skip forecast for stable weather return True Step 8: Testing Scheduled Executions 8.1 Manual Testing Test Current Weather Rule:\naws events put-events \\ --entries Source=weather.test,DetailType=\u0026#34;Manual Test\u0026#34;,Detail=\u0026#39;{\u0026#34;test\u0026#34;: true}\u0026#39; Verify S3 Data:\naws s3 ls s3://weather-data-lake-123456789012/raw/current-weather/ --recursive 8.2 Schedule Validation Check Rule Status:\naws events describe-rule --name weather-current-hourly List Targets:\naws events list-targets-by-rule --rule weather-current-hourly Troubleshooting Common Issues Issue 1: Lambda Not Triggered Check:\nRule state is \u0026ldquo;Enabled\u0026rdquo; Lambda permissions allow EventBridge Target configuration is correct Solution:\naws lambda add-permission \\ --function-name weather-current-collector \\ --statement-id allow-eventbridge \\ --action lambda:InvokeFunction \\ --principal events.amazonaws.com \\ --source-arn arn:aws:events:us-east-1:123456789012:rule/weather-current-hourly Issue 2: High API Usage Monitor Daily Usage:\ndef check_daily_api_usage(): \u0026#34;\u0026#34;\u0026#34;Check current API usage against limits.\u0026#34;\u0026#34;\u0026#34; # Query CloudWatch for daily API calls cloudwatch = boto3.client(\u0026#39;cloudwatch\u0026#39;) response = cloudwatch.get_metric_statistics( Namespace=\u0026#39;Weather/APIUsage\u0026#39;, MetricName=\u0026#39;APICalls\u0026#39;, Dimensions=[{\u0026#39;Name\u0026#39;: \u0026#39;Provider\u0026#39;, \u0026#39;Value\u0026#39;: \u0026#39;OpenWeatherMap\u0026#39;}], StartTime=datetime.now().replace(hour=0, minute=0, second=0), EndTime=datetime.now(), Period=86400, Statistics=[\u0026#39;Sum\u0026#39;] ) if response[\u0026#39;Datapoints\u0026#39;]: daily_usage = response[\u0026#39;Datapoints\u0026#39;][0][\u0026#39;Sum\u0026#39;] if daily_usage \u0026gt; 800: # 80% of 1000 limit # Disable collection or reduce frequency pass Next Steps Perfect! You now have automated weather data collection running on a schedule. In the next section, we\u0026rsquo;ll test the entire system and set up comprehensive monitoring to ensure everything works smoothly.\nWhat You\u0026rsquo;ve Accomplished:\nAutomated hourly current weather collection 6-hourly weather forecast collection CloudWatch monitoring and alarms SNS notifications for failures Dead letter queue for error handling Cost optimization strategies Optimization Tips:\nMonitor CloudWatch costs as metrics can add up Use CloudWatch Logs Insights for troubleshooting Consider using EventBridge rules for more complex scheduling Set up proper alerting thresholds based on your needs "
},
{
	"uri": "//localhost:1313/2-data-collection-openweathermap/2.4-testing-monitoring/",
	"title": "Testing and Monitoring Weather Collection",
	"tags": [],
	"description": "",
	"content": "Testing and Monitoring Weather Collection Now that we have our Lambda functions and automated scheduling configured, it\u0026rsquo;s time to thoroughly test the weather collection pipeline and set up comprehensive monitoring. We\u0026rsquo;ll validate data quality, performance, and ensure the system runs reliably.\nTesting Strategy Overview We\u0026rsquo;ll test our weather collection system using:\nManual Function Testing - Direct Lambda invocation Scheduled Execution Testing - CloudWatch Events validation Data Quality Validation - S3 data verification Performance Testing - Load and timing analysis Error Scenario Testing - Failure handling validation graph LR\rA[Manual Tests] --\u0026gt; B[Lambda Functions]\rC[Scheduled Tests] --\u0026gt; D[CloudWatch Events]\rE[Data Quality Tests] --\u0026gt; F[S3 Storage]\rG[Performance Tests] --\u0026gt; H[CloudWatch Metrics]\rI[Error Tests] --\u0026gt; J[Error Handling]\rstyle B fill:#ff9900,stroke:#232f3e,stroke-width:3px\rstyle F fill:#f3e5f5\rstyle H fill:#e8f5e8 Step 1: Manual Function Testing 1.1 Test Current Weather Function Navigate to Lambda Console\nAWS Console → Lambda → Functions Click weather-current-collector Create Test Event\n{ \u0026#34;source\u0026#34;: \u0026#34;manual-test\u0026#34;, \u0026#34;detail-type\u0026#34;: \u0026#34;Manual Test Event\u0026#34;, \u0026#34;detail\u0026#34;: { \u0026#34;test_mode\u0026#34;: true, \u0026#34;cities_to_test\u0026#34;: [\u0026#34;Ho Chi Minh City\u0026#34;, \u0026#34;Singapore\u0026#34;] } } Run Test\nClick \u0026ldquo;Test\u0026rdquo; button Wait for execution completion Review execution results Expected Response:\n{ \u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: \u0026#34;{\\\u0026#34;message\\\u0026#34;: \\\u0026#34;Weather collection completed\\\u0026#34;, \\\u0026#34;successful_collections\\\u0026#34;: 6, \\\u0026#34;failed_collections\\\u0026#34;: 0, \\\u0026#34;results\\\u0026#34;: [...]}\u0026#34; } 1.2 Test Weather Forecast Function Navigate to forecast function\nClick weather-forecast-collector Create Test Event\n{ \u0026#34;source\u0026#34;: \u0026#34;manual-test\u0026#34;, \u0026#34;detail-type\u0026#34;: \u0026#34;Manual Test Event\u0026#34;, \u0026#34;detail\u0026#34;: { \u0026#34;test_mode\u0026#34;: true, \u0026#34;include_extended_forecast\u0026#34;: true } } Verify Test Results\nCheck execution logs in CloudWatch Verify S3 objects are created Validate JSON structure Step 2: Data Quality Validation 2.1 S3 Data Structure Verification Check S3 Bucket Structure:\naws s3 ls s3://weather-data-lake-123456789012/ --recursive Expected Structure:\nweather-data-lake-123456789012/\r├── raw/\r│ ├── current-weather/\r│ │ └── year=2025/month=01/day=03/hour=14/\r│ │ ├── ho_chi_minh_city_20250103_140532.json\r│ │ ├── hanoi_20250103_140534.json\r│ │ ├── singapore_20250103_140536.json\r│ │ ├── bangkok_20250103_140538.json\r│ │ ├── jakarta_20250103_140540.json\r│ │ └── kuala_lumpur_20250103_140542.json\r│ └── forecast/\r│ └── year=2025/month=01/day=03/\r│ ├── ho_chi_minh_city_20250103_140612.json\r│ └── ... 2.2 Data Quality Validation Script File: validate_weather_data.py\nimport boto3 import json import pandas as pd from datetime import datetime, timedelta from typing import Dict, List, Optional import logging logging.basicConfig(level=logging.INFO) logger = logging.getLogger(__name__) class WeatherDataValidator: def __init__(self, bucket_name: str): self.s3 = boto3.client(\u0026#39;s3\u0026#39;) self.bucket_name = bucket_name def get_recent_files(self, data_type: str = \u0026#39;current-weather\u0026#39;, hours_back: int = 24) -\u0026gt; List[str]: \u0026#34;\u0026#34;\u0026#34;Get weather data files from the last N hours.\u0026#34;\u0026#34;\u0026#34; files = [] now = datetime.utcnow() for hour_offset in range(hours_back): check_time = now - timedelta(hours=hour_offset) prefix = f\u0026#34;raw/{data_type}/year={check_time.year}/month={check_time.month:02d}/day={check_time.day:02d}/\u0026#34; if data_type == \u0026#39;current-weather\u0026#39;: prefix += f\u0026#34;hour={check_time.hour:02d}/\u0026#34; try: response = self.s3.list_objects_v2( Bucket=self.bucket_name, Prefix=prefix ) for obj in response.get(\u0026#39;Contents\u0026#39;, []): files.append(obj[\u0026#39;Key\u0026#39;]) except Exception as e: logger.warning(f\u0026#34;Could not list objects for {prefix}: {e}\u0026#34;) return files def validate_current_weather_file(self, file_key: str) -\u0026gt; Dict: \u0026#34;\u0026#34;\u0026#34;Validate a current weather data file.\u0026#34;\u0026#34;\u0026#34; try: response = self.s3.get_object(Bucket=self.bucket_name, Key=file_key) data = json.loads(response[\u0026#39;Body\u0026#39;].read()) validation_results = { \u0026#39;file_key\u0026#39;: file_key, \u0026#39;valid\u0026#39;: True, \u0026#39;errors\u0026#39;: [], \u0026#39;warnings\u0026#39;: [] } # Required fields validation required_fields = [ \u0026#39;coord\u0026#39;, \u0026#39;weather\u0026#39;, \u0026#39;main\u0026#39;, \u0026#39;wind\u0026#39;, \u0026#39;clouds\u0026#39;, \u0026#39;dt\u0026#39;, \u0026#39;sys\u0026#39;, \u0026#39;timezone\u0026#39;, \u0026#39;id\u0026#39;, \u0026#39;name\u0026#39;, \u0026#39;cod\u0026#39; ] for field in required_fields: if field not in data: validation_results[\u0026#39;errors\u0026#39;].append(f\u0026#34;Missing required field: {field}\u0026#34;) validation_results[\u0026#39;valid\u0026#39;] = False # Temperature validation if \u0026#39;main\u0026#39; in data and \u0026#39;temp\u0026#39; in data[\u0026#39;main\u0026#39;]: temp = data[\u0026#39;main\u0026#39;][\u0026#39;temp\u0026#39;] if not (-50 \u0026lt;= temp \u0026lt;= 60): # Reasonable temperature range in Celsius validation_results[\u0026#39;warnings\u0026#39;].append(f\u0026#34;Temperature seems unusual: {temp}°C\u0026#34;) # Humidity validation if \u0026#39;main\u0026#39; in data and \u0026#39;humidity\u0026#39; in data[\u0026#39;main\u0026#39;]: humidity = data[\u0026#39;main\u0026#39;][\u0026#39;humidity\u0026#39;] if not (0 \u0026lt;= humidity \u0026lt;= 100): validation_results[\u0026#39;errors\u0026#39;].append(f\u0026#34;Invalid humidity value: {humidity}%\u0026#34;) validation_results[\u0026#39;valid\u0026#39;] = False # Collection metadata validation if \u0026#39;collection_metadata\u0026#39; in data: metadata = data[\u0026#39;collection_metadata\u0026#39;] required_metadata = [\u0026#39;collection_time\u0026#39;, \u0026#39;data_source\u0026#39;, \u0026#39;api_version\u0026#39;] for field in required_metadata: if field not in metadata: validation_results[\u0026#39;warnings\u0026#39;].append(f\u0026#34;Missing metadata field: {field}\u0026#34;) else: validation_results[\u0026#39;warnings\u0026#39;].append(\u0026#34;Missing collection_metadata\u0026#34;) # Data freshness check if \u0026#39;dt\u0026#39; in data: data_timestamp = datetime.fromtimestamp(data[\u0026#39;dt\u0026#39;]) age_hours = (datetime.utcnow() - data_timestamp).total_seconds() / 3600 if age_hours \u0026gt; 2: # Data older than 2 hours validation_results[\u0026#39;warnings\u0026#39;].append(f\u0026#34;Data is {age_hours:.1f} hours old\u0026#34;) return validation_results except Exception as e: return { \u0026#39;file_key\u0026#39;: file_key, \u0026#39;valid\u0026#39;: False, \u0026#39;errors\u0026#39;: [f\u0026#34;Failed to parse file: {str(e)}\u0026#34;], \u0026#39;warnings\u0026#39;: [] } def validate_forecast_file(self, file_key: str) -\u0026gt; Dict: \u0026#34;\u0026#34;\u0026#34;Validate a forecast data file.\u0026#34;\u0026#34;\u0026#34; try: response = self.s3.get_object(Bucket=self.bucket_name, Key=file_key) data = json.loads(response[\u0026#39;Body\u0026#39;].read()) validation_results = { \u0026#39;file_key\u0026#39;: file_key, \u0026#39;valid\u0026#39;: True, \u0026#39;errors\u0026#39;: [], \u0026#39;warnings\u0026#39;: [] } # Required fields for forecast required_fields = [\u0026#39;cod\u0026#39;, \u0026#39;message\u0026#39;, \u0026#39;cnt\u0026#39;, \u0026#39;list\u0026#39;, \u0026#39;city\u0026#39;] for field in required_fields: if field not in data: validation_results[\u0026#39;errors\u0026#39;].append(f\u0026#34;Missing required field: {field}\u0026#34;) validation_results[\u0026#39;valid\u0026#39;] = False # Validate forecast list if \u0026#39;list\u0026#39; in data: forecast_list = data[\u0026#39;list\u0026#39;] if len(forecast_list) == 0: validation_results[\u0026#39;errors\u0026#39;].append(\u0026#34;Empty forecast list\u0026#34;) validation_results[\u0026#39;valid\u0026#39;] = False # Check first few forecast items for i, forecast_item in enumerate(forecast_list[:3]): required_item_fields = [\u0026#39;dt\u0026#39;, \u0026#39;main\u0026#39;, \u0026#39;weather\u0026#39;, \u0026#39;wind\u0026#39;] for field in required_item_fields: if field not in forecast_item: validation_results[\u0026#39;errors\u0026#39;].append( f\u0026#34;Forecast item {i} missing field: {field}\u0026#34; ) validation_results[\u0026#39;valid\u0026#39;] = False return validation_results except Exception as e: return { \u0026#39;file_key\u0026#39;: file_key, \u0026#39;valid\u0026#39;: False, \u0026#39;errors\u0026#39;: [f\u0026#34;Failed to parse file: {str(e)}\u0026#34;], \u0026#39;warnings\u0026#39;: [] } def generate_validation_report(self) -\u0026gt; Dict: \u0026#34;\u0026#34;\u0026#34;Generate comprehensive validation report.\u0026#34;\u0026#34;\u0026#34; report = { \u0026#39;timestamp\u0026#39;: datetime.utcnow().isoformat(), \u0026#39;current_weather\u0026#39;: { \u0026#39;files_checked\u0026#39;: 0, \u0026#39;valid_files\u0026#39;: 0, \u0026#39;invalid_files\u0026#39;: 0, \u0026#39;total_errors\u0026#39;: 0, \u0026#39;total_warnings\u0026#39;: 0, \u0026#39;details\u0026#39;: [] }, \u0026#39;forecast\u0026#39;: { \u0026#39;files_checked\u0026#39;: 0, \u0026#39;valid_files\u0026#39;: 0, \u0026#39;invalid_files\u0026#39;: 0, \u0026#39;total_errors\u0026#39;: 0, \u0026#39;total_warnings\u0026#39;: 0, \u0026#39;details\u0026#39;: [] } } # Validate current weather files logger.info(\u0026#34;Validating current weather files...\u0026#34;) current_files = self.get_recent_files(\u0026#39;current-weather\u0026#39;, 6) # Last 6 hours for file_key in current_files: result = self.validate_current_weather_file(file_key) report[\u0026#39;current_weather\u0026#39;][\u0026#39;files_checked\u0026#39;] += 1 report[\u0026#39;current_weather\u0026#39;][\u0026#39;details\u0026#39;].append(result) if result[\u0026#39;valid\u0026#39;]: report[\u0026#39;current_weather\u0026#39;][\u0026#39;valid_files\u0026#39;] += 1 else: report[\u0026#39;current_weather\u0026#39;][\u0026#39;invalid_files\u0026#39;] += 1 report[\u0026#39;current_weather\u0026#39;][\u0026#39;total_errors\u0026#39;] += len(result[\u0026#39;errors\u0026#39;]) report[\u0026#39;current_weather\u0026#39;][\u0026#39;total_warnings\u0026#39;] += len(result[\u0026#39;warnings\u0026#39;]) # Validate forecast files logger.info(\u0026#34;Validating forecast files...\u0026#34;) forecast_files = self.get_recent_files(\u0026#39;forecast\u0026#39;, 24) # Last 24 hours for file_key in forecast_files: result = self.validate_forecast_file(file_key) report[\u0026#39;forecast\u0026#39;][\u0026#39;files_checked\u0026#39;] += 1 report[\u0026#39;forecast\u0026#39;][\u0026#39;details\u0026#39;].append(result) if result[\u0026#39;valid\u0026#39;]: report[\u0026#39;forecast\u0026#39;][\u0026#39;valid_files\u0026#39;] += 1 else: report[\u0026#39;forecast\u0026#39;][\u0026#39;invalid_files\u0026#39;] += 1 report[\u0026#39;forecast\u0026#39;][\u0026#39;total_errors\u0026#39;] += len(result[\u0026#39;errors\u0026#39;]) report[\u0026#39;forecast\u0026#39;][\u0026#39;total_warnings\u0026#39;] += len(result[\u0026#39;warnings\u0026#39;]) return report def main(): # Initialize validator validator = WeatherDataValidator(\u0026#39;weather-data-lake-123456789012\u0026#39;) # Replace with your bucket # Generate validation report report = validator.generate_validation_report() # Print summary print(\u0026#34;WEATHER DATA VALIDATION REPORT\u0026#34;) print(\u0026#34;=\u0026#34; * 50) print(f\u0026#34;Report Generated: {report[\u0026#39;timestamp\u0026#39;]}\u0026#34;) print() print(\u0026#34;CURRENT WEATHER DATA:\u0026#34;) print(f\u0026#34; Files Checked: {report[\u0026#39;current_weather\u0026#39;][\u0026#39;files_checked\u0026#39;]}\u0026#34;) print(f\u0026#34; Valid Files: {report[\u0026#39;current_weather\u0026#39;][\u0026#39;valid_files\u0026#39;]}\u0026#34;) print(f\u0026#34; Invalid Files: {report[\u0026#39;current_weather\u0026#39;][\u0026#39;invalid_files\u0026#39;]}\u0026#34;) print(f\u0026#34; Total Errors: {report[\u0026#39;current_weather\u0026#39;][\u0026#39;total_errors\u0026#39;]}\u0026#34;) print(f\u0026#34; Total Warnings: {report[\u0026#39;current_weather\u0026#39;][\u0026#39;total_warnings\u0026#39;]}\u0026#34;) print(\u0026#34;\\nFORECAST DATA:\u0026#34;) print(f\u0026#34; Files Checked: {report[\u0026#39;forecast\u0026#39;][\u0026#39;files_checked\u0026#39;]}\u0026#34;) print(f\u0026#34; Valid Files: {report[\u0026#39;forecast\u0026#39;][\u0026#39;valid_files\u0026#39;]}\u0026#34;) print(f\u0026#34; Invalid Files: {report[\u0026#39;forecast\u0026#39;][\u0026#39;invalid_files\u0026#39;]}\u0026#34;) print(f\u0026#34; Total Errors: {report[\u0026#39;forecast\u0026#39;][\u0026#39;total_errors\u0026#39;]}\u0026#34;) print(f\u0026#34; Total Warnings: {report[\u0026#39;forecast\u0026#39;][\u0026#39;total_warnings\u0026#39;]}\u0026#34;) # Show first few errors/warnings print(\u0026#34;\\nDETAILED ISSUES:\u0026#34;) for data_type in [\u0026#39;current_weather\u0026#39;, \u0026#39;forecast\u0026#39;]: for detail in report[data_type][\u0026#39;details\u0026#39;][:3]: # Show first 3 if detail[\u0026#39;errors\u0026#39;] or detail[\u0026#39;warnings\u0026#39;]: print(f\u0026#34;\\nFile: {detail[\u0026#39;file_key\u0026#39;]}\u0026#34;) for error in detail[\u0026#39;errors\u0026#39;]: print(f\u0026#34; ERROR: {error}\u0026#34;) for warning in detail[\u0026#39;warnings\u0026#39;]: print(f\u0026#34; WARNING: {warning}\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: main() Step 3: Performance Testing 3.1 Lambda Performance Analysis Create Performance Monitoring Script: monitor_lambda_performance.py\nimport boto3 import pandas as pd from datetime import datetime, timedelta import matplotlib.pyplot as plt import seaborn as sns class LambdaPerformanceMonitor: def __init__(self, region: str = \u0026#39;us-east-1\u0026#39;): self.cloudwatch = boto3.client(\u0026#39;cloudwatch\u0026#39;, region_name=region) self.lambda_client = boto3.client(\u0026#39;lambda\u0026#39;, region_name=region) def get_lambda_metrics(self, function_name: str, hours_back: int = 24) -\u0026gt; pd.DataFrame: \u0026#34;\u0026#34;\u0026#34;Get Lambda performance metrics.\u0026#34;\u0026#34;\u0026#34; end_time = datetime.utcnow() start_time = end_time - timedelta(hours=hours_back) metrics = [ \u0026#39;Duration\u0026#39;, \u0026#39;Errors\u0026#39;, \u0026#39;Invocations\u0026#39;, \u0026#39;Throttles\u0026#39;, \u0026#39;ConcurrentExecutions\u0026#39; ] all_data = [] for metric in metrics: try: response = self.cloudwatch.get_metric_statistics( Namespace=\u0026#39;AWS/Lambda\u0026#39;, MetricName=metric, Dimensions=[ { \u0026#39;Name\u0026#39;: \u0026#39;FunctionName\u0026#39;, \u0026#39;Value\u0026#39;: function_name } ], StartTime=start_time, EndTime=end_time, Period=3600, # 1 hour periods Statistics=[\u0026#39;Average\u0026#39;, \u0026#39;Maximum\u0026#39;, \u0026#39;Sum\u0026#39;] ) for datapoint in response.get(\u0026#39;Datapoints\u0026#39;, []): all_data.append({ \u0026#39;Timestamp\u0026#39;: datapoint[\u0026#39;Timestamp\u0026#39;], \u0026#39;MetricName\u0026#39;: metric, \u0026#39;Average\u0026#39;: datapoint.get(\u0026#39;Average\u0026#39;, 0), \u0026#39;Maximum\u0026#39;: datapoint.get(\u0026#39;Maximum\u0026#39;, 0), \u0026#39;Sum\u0026#39;: datapoint.get(\u0026#39;Sum\u0026#39;, 0) }) except Exception as e: print(f\u0026#34;Error getting metric {metric}: {e}\u0026#34;) return pd.DataFrame(all_data) def analyze_performance(self, function_name: str) -\u0026gt; Dict: \u0026#34;\u0026#34;\u0026#34;Analyze Lambda function performance.\u0026#34;\u0026#34;\u0026#34; df = self.get_lambda_metrics(function_name, 24) if df.empty: return {\u0026#39;error\u0026#39;: \u0026#39;No metrics data available\u0026#39;} analysis = { \u0026#39;function_name\u0026#39;: function_name, \u0026#39;analysis_time\u0026#39;: datetime.utcnow().isoformat(), \u0026#39;metrics\u0026#39;: {} } # Duration analysis duration_data = df[df[\u0026#39;MetricName\u0026#39;] == \u0026#39;Duration\u0026#39;] if not duration_data.empty: analysis[\u0026#39;metrics\u0026#39;][\u0026#39;duration\u0026#39;] = { \u0026#39;avg_duration_ms\u0026#39;: duration_data[\u0026#39;Average\u0026#39;].mean(), \u0026#39;max_duration_ms\u0026#39;: duration_data[\u0026#39;Maximum\u0026#39;].max(), \u0026#39;performance_trend\u0026#39;: \u0026#39;stable\u0026#39; if duration_data[\u0026#39;Average\u0026#39;].std() \u0026lt; 1000 else \u0026#39;variable\u0026#39; } # Error analysis error_data = df[df[\u0026#39;MetricName\u0026#39;] == \u0026#39;Errors\u0026#39;] total_errors = error_data[\u0026#39;Sum\u0026#39;].sum() if not error_data.empty else 0 invocation_data = df[df[\u0026#39;MetricName\u0026#39;] == \u0026#39;Invocations\u0026#39;] total_invocations = invocation_data[\u0026#39;Sum\u0026#39;].sum() if not invocation_data.empty else 0 error_rate = (total_errors / total_invocations * 100) if total_invocations \u0026gt; 0 else 0 analysis[\u0026#39;metrics\u0026#39;][\u0026#39;reliability\u0026#39;] = { \u0026#39;total_invocations\u0026#39;: total_invocations, \u0026#39;total_errors\u0026#39;: total_errors, \u0026#39;error_rate_percent\u0026#39;: error_rate, \u0026#39;reliability_status\u0026#39;: \u0026#39;good\u0026#39; if error_rate \u0026lt; 1 else \u0026#39;needs_attention\u0026#39; } # Throttling analysis throttle_data = df[df[\u0026#39;MetricName\u0026#39;] == \u0026#39;Throttles\u0026#39;] total_throttles = throttle_data[\u0026#39;Sum\u0026#39;].sum() if not throttle_data.empty else 0 analysis[\u0026#39;metrics\u0026#39;][\u0026#39;scaling\u0026#39;] = { \u0026#39;total_throttles\u0026#39;: total_throttles, \u0026#39;throttling_status\u0026#39;: \u0026#39;none\u0026#39; if total_throttles == 0 else \u0026#39;occurring\u0026#39; } return analysis def test_lambda_performance(): \u0026#34;\u0026#34;\u0026#34;Run performance tests on weather collection functions.\u0026#34;\u0026#34;\u0026#34; monitor = LambdaPerformanceMonitor() functions = [\u0026#39;weather-current-collector\u0026#39;, \u0026#39;weather-forecast-collector\u0026#39;] print(\u0026#34;LAMBDA PERFORMANCE ANALYSIS\u0026#34;) print(\u0026#34;=\u0026#34; * 50) for function_name in functions: print(f\u0026#34;\\nAnalyzing: {function_name}\u0026#34;) analysis = monitor.analyze_performance(function_name) if \u0026#39;error\u0026#39; in analysis: print(f\u0026#34; Error: {analysis[\u0026#39;error\u0026#39;]}\u0026#34;) continue # Duration metrics if \u0026#39;duration\u0026#39; in analysis[\u0026#39;metrics\u0026#39;]: duration = analysis[\u0026#39;metrics\u0026#39;][\u0026#39;duration\u0026#39;] print(f\u0026#34; Average Duration: {duration[\u0026#39;avg_duration_ms\u0026#39;]:.0f}ms\u0026#34;) print(f\u0026#34; Max Duration: {duration[\u0026#39;max_duration_ms\u0026#39;]:.0f}ms\u0026#34;) print(f\u0026#34; Performance: {duration[\u0026#39;performance_trend\u0026#39;]}\u0026#34;) # Reliability metrics if \u0026#39;reliability\u0026#39; in analysis[\u0026#39;metrics\u0026#39;]: reliability = analysis[\u0026#39;metrics\u0026#39;][\u0026#39;reliability\u0026#39;] print(f\u0026#34; Total Invocations: {reliability[\u0026#39;total_invocations\u0026#39;]}\u0026#34;) print(f\u0026#34; Error Rate: {reliability[\u0026#39;error_rate_percent\u0026#39;]:.2f}%\u0026#34;) print(f\u0026#34; Status: {reliability[\u0026#39;reliability_status\u0026#39;]}\u0026#34;) # Scaling metrics if \u0026#39;scaling\u0026#39; in analysis[\u0026#39;metrics\u0026#39;]: scaling = analysis[\u0026#39;metrics\u0026#39;][\u0026#39;scaling\u0026#39;] print(f\u0026#34; Throttles: {scaling[\u0026#39;total_throttles\u0026#39;]}\u0026#34;) print(f\u0026#34; Scaling Status: {scaling[\u0026#39;throttling_status\u0026#39;]}\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: test_lambda_performance() 3.2 API Usage Tracking Create API monitoring script: track_api_usage.py\nimport boto3 from datetime import datetime, timedelta def check_api_usage_limits(): \u0026#34;\u0026#34;\u0026#34;Monitor OpenWeatherMap API usage against limits.\u0026#34;\u0026#34;\u0026#34; cloudwatch = boto3.client(\u0026#39;cloudwatch\u0026#39;) # Get API usage for last 24 hours end_time = datetime.utcnow() start_time = end_time - timedelta(hours=24) try: response = cloudwatch.get_metric_statistics( Namespace=\u0026#39;Weather/APIUsage\u0026#39;, MetricName=\u0026#39;APICalls\u0026#39;, Dimensions=[ { \u0026#39;Name\u0026#39;: \u0026#39;Provider\u0026#39;, \u0026#39;Value\u0026#39;: \u0026#39;OpenWeatherMap\u0026#39; } ], StartTime=start_time, EndTime=end_time, Period=86400, # Daily period Statistics=[\u0026#39;Sum\u0026#39;] ) daily_usage = 0 if response[\u0026#39;Datapoints\u0026#39;]: daily_usage = response[\u0026#39;Datapoints\u0026#39;][0][\u0026#39;Sum\u0026#39;] # OpenWeatherMap free tier: 1000 calls/day usage_percentage = (daily_usage / 1000) * 100 print(\u0026#34;API USAGE MONITORING\u0026#34;) print(\u0026#34;=\u0026#34; * 30) print(f\u0026#34;24-hour API calls: {daily_usage}\u0026#34;) print(f\u0026#34;Daily limit: 1,000\u0026#34;) print(f\u0026#34;Usage: {usage_percentage:.1f}%\u0026#34;) if usage_percentage \u0026gt; 80: print(\u0026#34;⚠️ WARNING: Approaching daily limit!\u0026#34;) elif usage_percentage \u0026gt; 95: print(\u0026#34;🚨 CRITICAL: Very close to daily limit!\u0026#34;) else: print(\u0026#34;✅ Usage within safe limits\u0026#34;) # Calculate hourly rate hourly_rate = daily_usage / 24 projected_daily = hourly_rate * 24 print(f\u0026#34;\\nProjected daily usage: {projected_daily:.0f} calls\u0026#34;) print(f\u0026#34;Average hourly rate: {hourly_rate:.1f} calls/hour\u0026#34;) return { \u0026#39;daily_usage\u0026#39;: daily_usage, \u0026#39;usage_percentage\u0026#39;: usage_percentage, \u0026#39;hourly_rate\u0026#39;: hourly_rate } except Exception as e: print(f\u0026#34;Error checking API usage: {e}\u0026#34;) return None if __name__ == \u0026#34;__main__\u0026#34;: check_api_usage_limits() Step 4: Error Scenario Testing 4.1 Test API Key Failure Create test with invalid API key:\nTemporarily modify API key in Parameter Store\naws ssm put-parameter \\ --name \u0026#34;/weather-etl/openweathermap/api-key\u0026#34; \\ --value \u0026#34;invalid-key-for-testing\u0026#34; \\ --type \u0026#34;SecureString\u0026#34; \\ --overwrite Trigger Lambda function manually\nVerify error handling and CloudWatch logs\nRestore correct API key\n4.2 Test Network Failure Simulation Create network failure test script: test_error_scenarios.py\nimport boto3 import json from datetime import datetime def test_lambda_error_handling(): \u0026#34;\u0026#34;\u0026#34;Test error handling in Lambda functions.\u0026#34;\u0026#34;\u0026#34; lambda_client = boto3.client(\u0026#39;lambda\u0026#39;) # Test cases test_cases = [ { \u0026#39;name\u0026#39;: \u0026#39;API Timeout Simulation\u0026#39;, \u0026#39;payload\u0026#39;: { \u0026#39;test_scenario\u0026#39;: \u0026#39;api_timeout\u0026#39;, \u0026#39;cities\u0026#39;: [\u0026#39;Ho Chi Minh City\u0026#39;] } }, { \u0026#39;name\u0026#39;: \u0026#39;Invalid City Test\u0026#39;, \u0026#39;payload\u0026#39;: { \u0026#39;test_scenario\u0026#39;: \u0026#39;invalid_city\u0026#39;, \u0026#39;cities\u0026#39;: [\u0026#39;NonExistentCity\u0026#39;] } }, { \u0026#39;name\u0026#39;: \u0026#39;S3 Permission Test\u0026#39;, \u0026#39;payload\u0026#39;: { \u0026#39;test_scenario\u0026#39;: \u0026#39;s3_permission_test\u0026#39;, \u0026#39;cities\u0026#39;: [\u0026#39;Singapore\u0026#39;] } } ] functions = [\u0026#39;weather-current-collector\u0026#39;, \u0026#39;weather-forecast-collector\u0026#39;] print(\u0026#34;ERROR SCENARIO TESTING\u0026#34;) print(\u0026#34;=\u0026#34; * 40) for function_name in functions: print(f\u0026#34;\\nTesting function: {function_name}\u0026#34;) for test_case in test_cases: print(f\u0026#34; Running: {test_case[\u0026#39;name\u0026#39;]}\u0026#34;) try: response = lambda_client.invoke( FunctionName=function_name, InvocationType=\u0026#39;RequestResponse\u0026#39;, Payload=json.dumps(test_case[\u0026#39;payload\u0026#39;]) ) payload = json.loads(response[\u0026#39;Payload\u0026#39;].read()) status_code = payload.get(\u0026#39;statusCode\u0026#39;, 500) if status_code == 200: print(\u0026#34; ✅ Handled gracefully\u0026#34;) else: print(\u0026#34; ⚠️ Error occurred (expected for error tests)\u0026#34;) except Exception as e: print(f\u0026#34; ❌ Test failed: {e}\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: test_lambda_error_handling() Step 5: Comprehensive Monitoring Setup 5.1 Create CloudWatch Dashboard Dashboard JSON for comprehensive monitoring:\n{ \u0026#34;widgets\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;metric\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;metrics\u0026#34;: [ [ \u0026#34;AWS/Lambda\u0026#34;, \u0026#34;Invocations\u0026#34;, \u0026#34;FunctionName\u0026#34;, \u0026#34;weather-current-collector\u0026#34; ], [\u0026#34;.\u0026#34;, \u0026#34;Errors\u0026#34;, \u0026#34;.\u0026#34;, \u0026#34;.\u0026#34;], [\u0026#34;.\u0026#34;, \u0026#34;Duration\u0026#34;, \u0026#34;.\u0026#34;, \u0026#34;.\u0026#34;], [\u0026#34;.\u0026#34;, \u0026#34;Invocations\u0026#34;, \u0026#34;.\u0026#34;, \u0026#34;weather-forecast-collector\u0026#34;], [\u0026#34;.\u0026#34;, \u0026#34;Errors\u0026#34;, \u0026#34;.\u0026#34;, \u0026#34;.\u0026#34;], [\u0026#34;.\u0026#34;, \u0026#34;Duration\u0026#34;, \u0026#34;.\u0026#34;, \u0026#34;.\u0026#34;] ], \u0026#34;period\u0026#34;: 3600, \u0026#34;stat\u0026#34;: \u0026#34;Sum\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;us-east-1\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Lambda Function Metrics\u0026#34; } }, { \u0026#34;type\u0026#34;: \u0026#34;metric\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;metrics\u0026#34;: [ [ \u0026#34;Weather/ETL\u0026#34;, \u0026#34;SuccessfulCollections\u0026#34;, \u0026#34;DataType\u0026#34;, \u0026#34;CurrentWeather\u0026#34; ], [\u0026#34;.\u0026#34;, \u0026#34;FailedCollections\u0026#34;, \u0026#34;.\u0026#34;, \u0026#34;.\u0026#34;], [\u0026#34;.\u0026#34;, \u0026#34;SuccessfulCollections\u0026#34;, \u0026#34;.\u0026#34;, \u0026#34;Forecast\u0026#34;], [\u0026#34;.\u0026#34;, \u0026#34;FailedCollections\u0026#34;, \u0026#34;.\u0026#34;, \u0026#34;.\u0026#34;] ], \u0026#34;period\u0026#34;: 3600, \u0026#34;stat\u0026#34;: \u0026#34;Sum\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;us-east-1\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Collection Success Metrics\u0026#34; } }, { \u0026#34;type\u0026#34;: \u0026#34;metric\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;metrics\u0026#34;: [ [\u0026#34;Weather/APIUsage\u0026#34;, \u0026#34;APICalls\u0026#34;, \u0026#34;Provider\u0026#34;, \u0026#34;OpenWeatherMap\u0026#34;] ], \u0026#34;period\u0026#34;: 86400, \u0026#34;stat\u0026#34;: \u0026#34;Sum\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;us-east-1\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Daily API Usage\u0026#34; } } ] } 5.2 Set Up Automated Testing Create scheduled validation function: weather-data-validator\nimport boto3 import json from datetime import datetime, timedelta def lambda_handler(event, context): \u0026#34;\u0026#34;\u0026#34;Scheduled data validation function.\u0026#34;\u0026#34;\u0026#34; # This function runs daily to validate data quality validator = WeatherDataValidator(\u0026#39;weather-data-lake-123456789012\u0026#39;) report = validator.generate_validation_report() # Check for issues total_errors = (report[\u0026#39;current_weather\u0026#39;][\u0026#39;total_errors\u0026#39;] + report[\u0026#39;forecast\u0026#39;][\u0026#39;total_errors\u0026#39;]) if total_errors \u0026gt; 0: # Send alert to SNS sns = boto3.client(\u0026#39;sns\u0026#39;) sns.publish( TopicArn=\u0026#39;arn:aws:sns:us-east-1:123456789012:weather-collection-alerts\u0026#39;, Subject=\u0026#39;Weather Data Quality Issues Detected\u0026#39;, Message=f\u0026#34;Data validation found {total_errors} errors. Please check the dashboard.\u0026#34; ) # Store validation report in S3 s3 = boto3.client(\u0026#39;s3\u0026#39;) report_key = f\u0026#34;validation-reports/{datetime.utcnow().strftime(\u0026#39;%Y/%m/%d\u0026#39;)}/validation-report.json\u0026#34; s3.put_object( Bucket=\u0026#39;weather-data-lake-123456789012\u0026#39;, Key=report_key, Body=json.dumps(report, indent=2), ContentType=\u0026#39;application/json\u0026#39; ) return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps({ \u0026#39;validation_completed\u0026#39;: True, \u0026#39;total_errors\u0026#39;: total_errors, \u0026#39;report_location\u0026#39;: f\u0026#34;s3://weather-data-lake-123456789012/{report_key}\u0026#34; }) } Step 6: Cost Monitoring 6.1 Daily Cost Tracking Create cost monitoring script: monitor_daily_costs.py\nimport boto3 from datetime import datetime, timedelta def estimate_weather_collection_costs(): \u0026#34;\u0026#34;\u0026#34;Estimate daily costs for weather collection system.\u0026#34;\u0026#34;\u0026#34; # Get CloudWatch metrics for cost estimation cloudwatch = boto3.client(\u0026#39;cloudwatch\u0026#39;) end_time = datetime.utcnow() start_time = end_time - timedelta(hours=24) costs = { \u0026#39;lambda_invocations\u0026#39;: 0, \u0026#39;lambda_duration\u0026#39;: 0, \u0026#39;api_calls\u0026#39;: 0, \u0026#39;s3_storage\u0026#39;: 0, \u0026#39;cloudwatch_metrics\u0026#39;: 0, \u0026#39;total_estimated\u0026#39;: 0 } try: # Lambda invocations cost for function_name in [\u0026#39;weather-current-collector\u0026#39;, \u0026#39;weather-forecast-collector\u0026#39;]: response = cloudwatch.get_metric_statistics( Namespace=\u0026#39;AWS/Lambda\u0026#39;, MetricName=\u0026#39;Invocations\u0026#39;, Dimensions=[{\u0026#39;Name\u0026#39;: \u0026#39;FunctionName\u0026#39;, \u0026#39;Value\u0026#39;: function_name}], StartTime=start_time, EndTime=end_time, Period=86400, Statistics=[\u0026#39;Sum\u0026#39;] ) if response[\u0026#39;Datapoints\u0026#39;]: invocations = response[\u0026#39;Datapoints\u0026#39;][0][\u0026#39;Sum\u0026#39;] costs[\u0026#39;lambda_invocations\u0026#39;] += invocations * 0.0000002 # $0.20 per 1M requests # Lambda duration cost for function_name in [\u0026#39;weather-current-collector\u0026#39;, \u0026#39;weather-forecast-collector\u0026#39;]: response = cloudwatch.get_metric_statistics( Namespace=\u0026#39;AWS/Lambda\u0026#39;, MetricName=\u0026#39;Duration\u0026#39;, Dimensions=[{\u0026#39;Name\u0026#39;: \u0026#39;FunctionName\u0026#39;, \u0026#39;Value\u0026#39;: function_name}], StartTime=start_time, EndTime=end_time, Period=86400, Statistics=[\u0026#39;Sum\u0026#39;] ) if response[\u0026#39;Datapoints\u0026#39;]: total_duration_ms = response[\u0026#39;Datapoints\u0026#39;][0][\u0026#39;Sum\u0026#39;] gb_seconds = (total_duration_ms / 1000) * (256 / 1024) # 256MB memory costs[\u0026#39;lambda_duration\u0026#39;] += gb_seconds * 0.0000166667 # $0.0000166667 per GB-second # Estimate S3 storage cost (approximate) # Each weather file is ~2KB, 6 cities * 24 hours = 144 files/day for current weather # 6 cities * 4 times/day = 24 files/day for forecast daily_files = (6 * 24) + (6 * 4) # 168 files daily_storage_gb = (daily_files * 2) / (1024 * 1024) # Convert KB to GB costs[\u0026#39;s3_storage\u0026#39;] = daily_storage_gb * 0.023 # $0.023 per GB/month, daily portion # OpenWeatherMap API is free tier (up to 1000 calls/day) costs[\u0026#39;api_calls\u0026#39;] = 0 # CloudWatch metrics cost (approximate) # Custom metrics: $0.30 per metric per month custom_metrics = 3 # APICalls, SuccessfulCollections, FailedCollections costs[\u0026#39;cloudwatch_metrics\u0026#39;] = (custom_metrics * 0.30) / 30 # Daily portion costs[\u0026#39;total_estimated\u0026#39;] = sum(costs.values()) print(\u0026#34;DAILY COST ESTIMATION\u0026#34;) print(\u0026#34;=\u0026#34; * 30) print(f\u0026#34;Lambda Invocations: ${costs[\u0026#39;lambda_invocations\u0026#39;]:.6f}\u0026#34;) print(f\u0026#34;Lambda Duration: ${costs[\u0026#39;lambda_duration\u0026#39;]:.6f}\u0026#34;) print(f\u0026#34;S3 Storage: ${costs[\u0026#39;s3_storage\u0026#39;]:.6f}\u0026#34;) print(f\u0026#34;API Calls: ${costs[\u0026#39;api_calls\u0026#39;]:.6f} (Free Tier)\u0026#34;) print(f\u0026#34;CloudWatch Metrics: ${costs[\u0026#39;cloudwatch_metrics\u0026#39;]:.6f}\u0026#34;) print(f\u0026#34;Total Daily Cost: ${costs[\u0026#39;total_estimated\u0026#39;]:.6f}\u0026#34;) print(f\u0026#34;Monthly Projection: ${costs[\u0026#39;total_estimated\u0026#39;] * 30:.2f}\u0026#34;) return costs except Exception as e: print(f\u0026#34;Error calculating costs: {e}\u0026#34;) return None if __name__ == \u0026#34;__main__\u0026#34;: estimate_weather_collection_costs() Step 7: Testing Results Summary Expected Test Results ✅ Successful Test Indicators:\nLambda Functions:\nCurrent weather function executes in \u0026lt; 30 seconds Forecast function executes in \u0026lt; 45 seconds Error rate \u0026lt; 1% No throttling issues Data Quality:\nAll required fields present in JSON Temperature values within reasonable range (-50°C to +60°C) Humidity values 0-100% Timestamps within expected range Scheduling:\nCloudWatch Events trigger correctly Functions execute on schedule No missed executions Cost Efficiency:\nDaily cost \u0026lt; $0.10 Monthly projection \u0026lt; $3.00 API usage \u0026lt; 500 calls/day (50% of free tier) Troubleshooting Common Issues Issue 1: Lambda Timeout\nIncrease timeout to 5 minutes Check network connectivity Optimize API request handling Issue 2: Invalid Weather Data\nVerify API key validity Check city coordinates Validate JSON parsing Issue 3: S3 Permission Errors\nReview IAM role permissions Check bucket policy Verify bucket exists Issue 4: High API Usage\nReduce collection frequency Implement smart caching Monitor daily limits Next Steps Excellent! You now have a fully tested weather data collection system with comprehensive monitoring. The system is ready for production use.\nTesting Completed:\n✅ Manual function testing ✅ Data quality validation ✅ Performance monitoring ✅ Error scenario testing ✅ Cost tracking ✅ Automated monitoring setup Production Monitoring:\nSet up daily validation reports Monitor API usage trends Review cost projections weekly Test error scenarios monthly Update city lists as needed In the next module, we\u0026rsquo;ll build serverless data processing with Lambda to transform and analyze this weather data!\n"
},
{
	"uri": "//localhost:1313/1-introduction/",
	"title": "Introduction and Architecture",
	"tags": [],
	"description": "",
	"content": "Building a Serverless Weather ETL Pipeline Welcome to this hands-on workshop where you\u0026rsquo;ll build a complete Extract, Transform, Load (ETL) pipeline using AWS serverless services to collect, process, and visualize weather data.\nWorkshop Overview In this workshop, you\u0026rsquo;ll create a simplified but complete weather data pipeline that demonstrates core ETL concepts using AWS serverless technologies. The workshop is designed to be completed in 2-3 hours with an estimated cost of under $10 for the entire experience.\nLearning Objectives By the end of this workshop, you will:\nBuild a serverless data collection system using AWS Lambda Implement data transformation and processing workflows Store and query data using Amazon S3 and Athena Create visualizations with Amazon QuickSight Apply AWS best practices for cost optimization and resource cleanup Architecture Overview Our weather ETL pipeline follows this simplified serverless architecture:\nOpenWeatherMap API → Lambda Collector → S3 Raw Data → Lambda Processor → S3 Processed Data → Athena Analytics → QuickSight Dashboard Key Components:\nData Source: OpenWeatherMap API for real-time weather data Collection: AWS Lambda function to fetch weather data Storage: Amazon S3 for both raw and processed data Processing: AWS Lambda for data transformation Analytics: Amazon Athena for SQL queries Visualization: Amazon QuickSight for dashboards Workshop Modules This workshop is organized into 6 modules:\nModule 1: Introduction and Architecture Workshop overview and learning objectives Architecture design and AWS services introduction Prerequisites and setup requirements Module 2: Weather Data Collection with OpenWeatherMap Setting up OpenWeatherMap API account Creating Lambda function for data collection Configuring automated data retrieval Testing and monitoring the collection process Module 3: Serverless Data Processing with Lambda Building data transformation Lambda function Converting raw weather JSON to analytical format Implementing data validation and enrichment Setting up processing triggers Module 4: Data Analysis with Amazon Athena Creating S3 data lake structure Setting up Athena tables and schemas Writing SQL queries for weather analysis Exploring data patterns and insights Module 5: Data Visualization with QuickSight Setting up Amazon QuickSight Creating weather dashboards Building interactive visualizations Sharing and publishing dashboards Module 6: Resource Cleanup and Next Steps Comprehensive cleanup checklist Cost optimization strategies Suggested improvements and extensions Additional learning resources Prerequisites Before starting this workshop, ensure you have:\nAWS Account with administrative access Basic familiarity with AWS console Understanding of basic programming concepts OpenWeatherMap account (free tier sufficient) Estimated Costs This workshop is designed to be cost-effective:\nOpenWeatherMap API: Free (up to 1,000 calls/day) AWS Lambda: ~$1-2 (well within free tier) Amazon S3: ~$1-2 for storage Amazon Athena: ~$2-3 for queries Amazon QuickSight: ~$3-4 (30-day free trial available) Total estimated cost: Under $10 for the complete workshop\nGetting Started Ready to begin? Let\u0026rsquo;s start with Module 2: Weather Data Collection with OpenWeatherMap where you\u0026rsquo;ll set up your data source and create your first Lambda function.\nNote: Remember to follow the cleanup procedures in Module 6 to avoid ongoing charges after completing the workshop.\n"
},
{
	"uri": "//localhost:1313/2-data-collection-openweathermap/",
	"title": "Weather Data Collection with Lambda",
	"tags": [],
	"description": "",
	"content": "Weather Data Collection with Lambda In this module, you\u0026rsquo;ll build an automated weather data collection system using AWS Lambda functions and the OpenWeatherMap API. This serverless approach provides a scalable, cost-effective solution for gathering weather data from multiple cities on a scheduled basis.\nModule Learning Objectives By the end of this module, you will:\nSet up OpenWeatherMap API access and understand rate limits Create Lambda functions to collect current weather and forecast data Implement automated scheduling using CloudWatch Events Store weather data in S3 with proper partitioning Set up monitoring and error handling Test the complete data collection pipeline Architecture Overview graph TB A[CloudWatch Events\u0026lt;br/\u0026gt;Scheduler] --\u0026gt; B[Lambda Functions] B --\u0026gt; C[OpenWeatherMap API] C --\u0026gt; D[Weather Data Response] D --\u0026gt; B B --\u0026gt; E[S3 Data Lake\u0026lt;br/\u0026gt;Partitioned Storage] B --\u0026gt; F[CloudWatch Metrics] G[Parameter Store\u0026lt;br/\u0026gt;API Keys] --\u0026gt; B H[SNS Alerts] --\u0026gt; I[Email Notifications] F --\u0026gt; H style B fill:#ff9900,stroke:#232f3e,stroke-width:3px style E fill:#f3e5f5 style C fill:#e1f5fe What You\u0026rsquo;ll Build Data Collection Components Lambda Functions: Serverless data collectors for current weather and forecasts CloudWatch Events: Automated scheduling (hourly for current weather, 6-hourly for forecasts) S3 Storage: Organized data lake with year/month/day/hour partitioning Parameter Store: Secure API key management Monitoring and Alerting CloudWatch Metrics: Custom metrics for collection success/failure rates CloudWatch Alarms: Automated alerts for system issues SNS Notifications: Email alerts for failures and API limit warnings Data Sources Current Weather: Real-time conditions for 6 Southeast Asian cities 5-Day Forecasts: Weather predictions with 3-hour intervals API Metadata: Collection timestamps and data quality indicators Target Cities The workshop collects weather data for these cities:\nCity Country Coordinates Timezone Ho Chi Minh City Vietnam 10.8231, 106.6297 UTC+7 Hanoi Vietnam 21.0285, 105.8542 UTC+7 Singapore Singapore 1.3521, 103.8198 UTC+8 Bangkok Thailand 13.7563, 100.5018 UTC+7 Jakarta Indonesia -6.2088, 106.8456 UTC+7 Kuala Lumpur Malaysia 3.1390, 101.6869 UTC+8 Expected Data Volume Daily Collection Estimates Current Weather: 6 cities × 24 hours = 144 files/day (~288 KB) Weather Forecasts: 6 cities × 4 collections = 24 files/day (~480 KB) Total Daily Storage: ~768 KB (~23 MB/month) API Usage Current Weather: 144 API calls/day Forecasts: 24 API calls/day Total Daily API Calls: 168 (well within 1,000 free tier limit) Cost Breakdown Estimated Monthly Costs Lambda Invocations: ~$0.01 (168 daily invocations) Lambda Duration: ~$0.15 (average 5-second executions) S3 Storage: ~$0.01 (23 MB monthly storage) CloudWatch Metrics: ~$0.90 (custom metrics) API Calls: $0.00 (free tier) Total Module Cost: ~$1.07/month\nModule Structure This module is divided into four sections:\n2.1 OpenWeatherMap Setup Create OpenWeatherMap account Obtain API key and understand limits Test API endpoints Store credentials securely 2.2 Building Lambda Weather Collector Create IAM roles and policies Develop Lambda functions for data collection Implement error handling and retry logic Configure environment variables 2.3 Automated Scheduling Set up CloudWatch Events rules Configure different schedules for different data types Implement monitoring and alerting Create SNS topics for notifications 2.4 Testing and Monitoring Test Lambda functions manually Validate data quality and structure Set up comprehensive monitoring Perform load and error testing Key Technologies Used AWS Services AWS Lambda: Serverless compute for data collection Amazon S3: Scalable object storage for data lake Amazon CloudWatch: Monitoring, logging, and scheduling Amazon SNS: Notification service for alerts AWS Systems Manager: Parameter Store for secure configuration Development Tools Python 3.11: Primary programming language Boto3: AWS SDK for Python Requests: HTTP library for API calls JSON: Data format for weather information External Services OpenWeatherMap API: Weather data provider REST APIs: HTTP-based data exchange Best Practices Implemented Security IAM roles with least privilege access Encrypted storage for API keys VPC endpoints for internal AWS communication No hardcoded credentials in code Reliability Comprehensive error handling and retry logic Dead letter queues for failed executions Health checks and monitoring Graceful degradation on partial failures Scalability Serverless architecture with auto-scaling Partitioned data storage for efficient querying Batch processing for multiple cities Rate limiting compliance with API providers Cost Optimization Efficient Lambda memory allocation S3 lifecycle policies for data archival CloudWatch log retention management API usage monitoring and optimization Prerequisites for This Module Before starting, ensure you have:\nAWS account with Lambda, S3, CloudWatch access AWS CLI configured with appropriate permissions OpenWeatherMap account (free registration) Basic Python programming knowledge Understanding of JSON data structures Success Criteria By the end of this module, you should have:\nAutomated weather data collection running every hour Weather forecast collection running every 6 hours Properly structured data stored in S3 Monitoring dashboard showing collection metrics Error alerting system via email notifications API usage tracking staying within free tier limits Ready to start collecting weather data? Let\u0026rsquo;s begin with setting up your OpenWeatherMap API access!\nModule Duration: Approximately 90 minutes\nSection 2.1: 20 minutes (API setup) Section 2.2: 35 minutes (Lambda development) Section 2.3: 25 minutes (Scheduling setup) Section 2.4: 10 minutes (Testing) Important: Keep track of your OpenWeatherMap API key and AWS resource names as you\u0026rsquo;ll need them in subsequent modules.\n"
},
{
	"uri": "//localhost:1313/3-serverless-processing-lambda/",
	"title": "Data Processing and Transformation",
	"tags": [],
	"description": "",
	"content": "Data Processing and Transformation In this module, you\u0026rsquo;ll build a Lambda function to process and transform the raw weather data collected from OpenWeatherMap API into a more analytics-friendly format. This transformation step is essential in any ETL pipeline to prepare data for efficient analysis.\nModule Overview Raw weather data from APIs often contains complex nested structures, inconsistent formats, and extraneous information. In this module, we\u0026rsquo;ll transform this raw data into a clean, structured format optimized for analytics.\nWhat You\u0026rsquo;ll Build graph LR A[S3 Raw Data] --\u0026gt; B[Lambda Processor] B --\u0026gt; C[S3 Processed Data] D[CloudWatch Events] --\u0026gt; B style B fill:#ff9900,stroke:#232f3e,stroke-width:3px style A fill:#f3e5f5 style C fill:#f3e5f5 Key Transformation Steps Our Lambda processor will perform these key transformations:\nData Flattening: Convert nested JSON structures to flat records Unit Conversion: Convert temperature from Kelvin to Celsius and Fahrenheit Data Enrichment: Add derived fields like heat index and comfort level Format Standardization: Ensure consistent field names and data types Data Validation: Filter out invalid or incomplete records Lambda Processor Function You\u0026rsquo;ll create a Python Lambda function that:\nRetrieves raw weather data from the S3 bucket Applies transformation logic Stores processed results in a separate S3 location Handles errors gracefully Sample Code Structure import json import boto3 import datetime s3_client = boto3.client(\u0026#39;s3\u0026#39;) def lambda_handler(event, context): # Get raw data from S3 raw_bucket = \u0026#39;weather-data-raw\u0026#39; processed_bucket = \u0026#39;weather-data-processed\u0026#39; # Process each file in the event for record in event[\u0026#39;Records\u0026#39;]: # Get the file key key = record[\u0026#39;s3\u0026#39;][\u0026#39;object\u0026#39;][\u0026#39;key\u0026#39;] # Get the raw data response = s3_client.get_object(Bucket=raw_bucket, Key=key) raw_data = json.loads(response[\u0026#39;Body\u0026#39;].read().decode(\u0026#39;utf-8\u0026#39;)) # Transform the data processed_data = transform_weather_data(raw_data) # Save to processed bucket processed_key = key.replace(\u0026#39;raw\u0026#39;, \u0026#39;processed\u0026#39;) s3_client.put_object( Bucket=processed_bucket, Key=processed_key, Body=json.dumps(processed_data), ContentType=\u0026#39;application/json\u0026#39; ) return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: f\u0026#39;Processed {len(event[\u0026#34;Records\u0026#34;])} files\u0026#39; } def transform_weather_data(raw_data): # Implement transformation logic here # ... Data Transformation Examples Raw OpenWeatherMap Data { \u0026#34;coord\u0026#34;: { \u0026#34;lon\u0026#34;: 106.6297, \u0026#34;lat\u0026#34;: 10.8231 }, \u0026#34;weather\u0026#34;: [ { \u0026#34;id\u0026#34;: 803, \u0026#34;main\u0026#34;: \u0026#34;Clouds\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;broken clouds\u0026#34;, \u0026#34;icon\u0026#34;: \u0026#34;04d\u0026#34; } ], \u0026#34;main\u0026#34;: { \u0026#34;temp\u0026#34;: 305.15, \u0026#34;feels_like\u0026#34;: 309.65, \u0026#34;temp_min\u0026#34;: 305.15, \u0026#34;temp_max\u0026#34;: 305.15, \u0026#34;pressure\u0026#34;: 1013, \u0026#34;humidity\u0026#34;: 74 }, \u0026#34;wind\u0026#34;: { \u0026#34;speed\u0026#34;: 3.2, \u0026#34;deg\u0026#34;: 220 }, \u0026#34;clouds\u0026#34;: { \u0026#34;all\u0026#34;: 75 }, \u0026#34;dt\u0026#34;: 1642248000, \u0026#34;sys\u0026#34;: { \u0026#34;country\u0026#34;: \u0026#34;VN\u0026#34;, \u0026#34;sunrise\u0026#34;: 1642203600, \u0026#34;sunset\u0026#34;: 1642245600 }, \u0026#34;timezone\u0026#34;: 25200, \u0026#34;id\u0026#34;: 1566083, \u0026#34;name\u0026#34;: \u0026#34;Ho Chi Minh City\u0026#34; } Transformed Data { \u0026#34;timestamp\u0026#34;: \u0026#34;2025-01-15T09:00:00Z\u0026#34;, \u0026#34;city_name\u0026#34;: \u0026#34;Ho Chi Minh City\u0026#34;, \u0026#34;country\u0026#34;: \u0026#34;VN\u0026#34;, \u0026#34;latitude\u0026#34;: 10.8231, \u0026#34;longitude\u0026#34;: 106.6297, \u0026#34;temperature_celsius\u0026#34;: 32.0, \u0026#34;temperature_fahrenheit\u0026#34;: 89.6, \u0026#34;feels_like_celsius\u0026#34;: 36.5, \u0026#34;humidity_percent\u0026#34;: 74, \u0026#34;pressure_hpa\u0026#34;: 1013, \u0026#34;weather_main\u0026#34;: \u0026#34;Clouds\u0026#34;, \u0026#34;weather_description\u0026#34;: \u0026#34;broken clouds\u0026#34;, \u0026#34;wind_speed_ms\u0026#34;: 3.2, \u0026#34;wind_direction_deg\u0026#34;: 220, \u0026#34;cloud_coverage_percent\u0026#34;: 75, \u0026#34;heat_index\u0026#34;: 38.2, \u0026#34;comfort_level\u0026#34;: \u0026#34;uncomfortable\u0026#34;, \u0026#34;data_collection_date\u0026#34;: \u0026#34;2025-01-15\u0026#34; } Implementation Steps Create Lambda Function: Set up a new Lambda for data processing Configure S3 Trigger: Set up event notifications from raw data bucket Implement Transformation Logic: Write code to transform weather data Set Up Error Handling: Add robust error handling and logging Test the Function: Verify transformation with test data Benefits of Data Transformation Improved Query Performance: Flat structures are easier to query Reduced Storage Costs: Optimized data formats use less storage Enhanced Analytics: Derived fields enable deeper insights Better Data Quality: Validation ensures reliable data Next Steps After completing this module, you\u0026rsquo;ll have a fully functional data transformation pipeline that prepares your weather data for analysis. In the next module, we\u0026rsquo;ll use Amazon Athena to query and analyze this processed data.\nData transformation is where you can add your domain-specific knowledge. Consider what additional weather metrics might be useful for your specific analysis needs.\n"
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]