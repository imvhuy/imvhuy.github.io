[
{
	"uri": "//localhost:1313/1-introduction-architecture/",
	"title": "Introduction &amp; Architecture Design",
	"tags": [],
	"description": "",
	"content": "Workshop Overview Welcome to this comprehensive workshop on building an ETL Data Pipeline for E-commerce using AWS services! This hands-on session will guide you through creating a modern, serverless data processing system that can handle real-world e-commerce scenarios.\nWhat is ETL? ETL stands for Extract, Transform, Load - a fundamental data integration process:\nExtract: Collect data from various sources (websites, databases, APIs) Transform: Clean, validate, and restructure data for analysis Load: Store processed data in target systems for analytics In e-commerce, ETL pipelines are crucial for:\nProcessing customer orders in real-time Analyzing user behavior and website interactions Managing inventory and supply chain data Generating business intelligence reports Why AWS for ETL? AWS provides powerful, cost-effective services for building modern data pipelines:\nServerless Architecture - No server management, automatic scaling Pay-as-you-go - Only pay for what you use Managed Services - Focus on business logic, not infrastructure Real-time Processing - Handle streaming data efficiently Integration - Services work seamlessly together\nArchitecture Overview Our ETL pipeline will implement a modern data architecture with the following components:\n1. Data Sources (Real E-commerce API) We\u0026rsquo;ll use DummyJSON API to get realistic e-commerce data:\nProducts: 100+ real product catalog from DummyJSON /products endpoint Users: 30 customer profiles from /users endpoint Carts: 20 shopping cart transactions from /carts endpoint Posts \u0026amp; Comments: User-generated content for reviews simulation Batch Processing: Daily data collection and analysis 2. Data Collection Layer AWS Lambda (Scheduled) will collect data from DummyJSON:\nServerless, cost-effective data collection Scheduled execution using CloudWatch Events No infrastructure management required Built-in retry and error handling 3. Data Processing Layer AWS Lambda functions will transform and store data:\nClean and normalize DummyJSON data Transform JSON to Parquet format Partition data by date for efficient querying Generate analytics-ready datasets 4. Data Storage Layer Amazon S3 as our Data Lake:\nScalable, durable object storage Partitioned by date for efficient queries Multiple formats: Raw JSON and Parquet Cost-optimized with S3 Intelligent Tiering 5. Analytics Layer Amazon Athena for SQL queries:\nServerless query service Query data directly in S3 Standard SQL interface Amazon QuickSight for visualization:\nBusiness intelligence service Interactive dashboards Mobile-friendly reports 6. Monitoring \u0026amp; Management Amazon CloudWatch:\nMonitor system health and performance Set up alerts and notifications Track costs and resource usage Data Flow Architecture graph TD\rA[DummyJSON API] --\u0026gt; B[Lambda Collector]\rC[CloudWatch Events] --\u0026gt; B\rB --\u0026gt; D[Lambda Processor]\rD --\u0026gt; E[S3 Data Lake]\rE --\u0026gt; F[Athena]\rF --\u0026gt; G[QuickSight]\rH[CloudWatch Logs] --\u0026gt; B\rH --\u0026gt; D ETL Data Flow: CloudWatch Events triggers Lambda on schedule (daily) Lambda Collector fetches data from DummyJSON API endpoints Lambda Processor transforms and validates data S3 Data Lake stores both raw and processed data Athena queries data using standard SQL QuickSight creates interactive dashboards and reports Sample Data Schema Our pipeline will process real data from DummyJSON API. Here are the actual data structures:\nDummyJSON Product Data { \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;iPhone 9\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;An apple mobile which is nothing like apple\u0026#34;, \u0026#34;price\u0026#34;: 549, \u0026#34;discountPercentage\u0026#34;: 12.96, \u0026#34;rating\u0026#34;: 4.69, \u0026#34;stock\u0026#34;: 94, \u0026#34;brand\u0026#34;: \u0026#34;Apple\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;smartphones\u0026#34;, \u0026#34;thumbnail\u0026#34;: \u0026#34;https://dummyjson.com/image/i/products/1/thumbnail.jpg\u0026#34;, \u0026#34;images\u0026#34;: [\u0026#34;https://dummyjson.com/image/i/products/1/1.jpg\u0026#34;] } DummyJSON User Data { \u0026#34;id\u0026#34;: 1, \u0026#34;firstName\u0026#34;: \u0026#34;Emily\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Johnson\u0026#34;, \u0026#34;maidenName\u0026#34;: \u0026#34;Smith\u0026#34;, \u0026#34;age\u0026#34;: 28, \u0026#34;gender\u0026#34;: \u0026#34;female\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;emily.johnson@x.dummyjson.com\u0026#34;, \u0026#34;phone\u0026#34;: \u0026#34;+81 965-431-3024\u0026#34;, \u0026#34;address\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;626 Main Street\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;Phoenix\u0026#34;, \u0026#34;coordinates\u0026#34;: { \u0026#34;lat\u0026#34;: 33.4484, \u0026#34;lng\u0026#34;: -112.074 }, \u0026#34;postalCode\u0026#34;: \u0026#34;85001\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;Arizona\u0026#34; } } Transformed E-commerce Event { \u0026#34;event_type\u0026#34;: \u0026#34;product_purchase\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2025-01-15T10:30:00Z\u0026#34;, \u0026#34;transaction_id\u0026#34;: \u0026#34;txn_123456\u0026#34;, \u0026#34;user_id\u0026#34;: 1, \u0026#34;product\u0026#34;: { \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;iPhone 9\u0026#34;, \u0026#34;price\u0026#34;: 549, \u0026#34;category\u0026#34;: \u0026#34;smartphones\u0026#34;, \u0026#34;brand\u0026#34;: \u0026#34;Apple\u0026#34; }, \u0026#34;quantity\u0026#34;: 1, \u0026#34;total_amount\u0026#34;: 549, \u0026#34;user_location\u0026#34;: { \u0026#34;city\u0026#34;: \u0026#34;Phoenix\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;Arizona\u0026#34;, \u0026#34;country\u0026#34;: \u0026#34;USA\u0026#34; } } Expected Outcomes By the end of this workshop, you\u0026rsquo;ll have built:\nüéØ A complete ETL pipeline processing real e-commerce data from DummyJSON üìä Interactive dashboards showing product, user, and sales analytics üîß Serverless architecture with minimal infrastructure management üí∞ Cost-optimized solution under $3/month using AWS Free Tier üìà Batch analytics capabilities for business insights and reporting\nPrerequisites Check Before we start building, ensure you have:\n‚úÖ AWS Account with administrative access ‚úÖ AWS CLI installed and configured (optional) ‚úÖ Basic understanding of JSON data format and REST APIs ‚úÖ Internet connection to access DummyJSON API (https://dummyjson.com) ‚úÖ Text editor for code editing ‚úÖ Web browser for AWS Console access DummyJSON API Endpoints We\u0026rsquo;ll Use: üõçÔ∏è Products: https://dummyjson.com/products (100 realistic products) üë• Users: https://dummyjson.com/users (30 sample users) üõí Carts: https://dummyjson.com/carts (20 shopping carts) üìù Posts: https://dummyjson.com/posts (150 posts for review simulation) üí¨ Comments: https://dummyjson.com/comments (340 comments) Cost Management: While this workshop uses AWS Free Tier services, always monitor your usage and set up billing alerts to avoid unexpected charges.\nWorkshop Structure This workshop is divided into 8 hands-on modules:\n[Current] Introduction \u0026amp; Architecture Design [Next] Data Collection with Lambda Data Processing and Transformation Setting up S3 Data Lake Analytics with Amazon Athena Visualization with QuickSight Monitoring and Optimization Cleanup and Next Steps Ready to start building? Let\u0026rsquo;s move to the next module where we\u0026rsquo;ll create our Lambda function to collect data from DummyJSON!\nEstimated Time: This module took approximately 15 minutes to complete. The next module will involve hands-on Lambda function creation and DummyJSON integration.\n"
},
{
	"uri": "//localhost:1313/",
	"title": "Building ETL Data Pipeline for E-commerce on AWS",
	"tags": [],
	"description": "",
	"content": "Building ETL Data Pipeline for E-commerce on AWS Overview In this comprehensive workshop, you will learn how to build a serverless ETL (Extract, Transform, Load) data pipeline for an e-commerce platform using AWS services and real data from DummyJSON API. This hands-on workshop will guide you through creating a simple, cost-effective data processing system that collects, transforms, and analyzes real e-commerce data including products, users, and shopping carts.\nWhat You\u0026rsquo;ll Build You will create a complete serverless data pipeline that:\nCollects real e-commerce data from DummyJSON API Processes and transforms data using AWS Lambda Stores structured data in S3 Data Lake Analyzes data using Amazon Athena Visualizes business insights through QuickSight dashboards This workshop is designed for developers, data engineers, and cloud architects who want to gain hands-on experience with AWS data services. Prior knowledge of AWS basics and some programming experience (Python/SQL) is recommended but not required.\nAWS Services You\u0026rsquo;ll Learn Data Collection:\nAWS Lambda - Serverless compute for data collection and processing CloudWatch Events - Scheduled execution and automation Data Storage:\nAmazon S3 - Scalable object storage for data lakes S3 Intelligent Tiering - Cost optimization for data storage Analytics \u0026amp; Visualization:\nAmazon Athena - Interactive query service for S3 data Amazon QuickSight - Business intelligence and visualization Monitoring \u0026amp; Management:\nAmazon CloudWatch - Monitoring, logging, and alerting AWS IAM - Identity and access management External Integration:\nDummyJSON API - Real e-commerce data source Business Use Cases This ETL pipeline demonstrates real e-commerce analytics scenarios:\nProduct Analytics - Product performance analysis and inventory insights Customer Analytics - User demographics and behavior patterns Sales Analysis - Shopping cart analysis and conversion tracking Market Research - Product category trends and pricing analysis Business Intelligence - Executive dashboards and KPI reporting Architecture Components Data Sources - DummyJSON API (products, users, carts, posts, comments) Collection Layer - Scheduled Lambda functions for data retrieval Processing Layer - Lambda functions for data transformation and partitioning Storage Layer - S3 Data Lake with optimized structure Analytics Layer - Athena for SQL querying and QuickSight for visualization Monitoring - CloudWatch for logging, metrics, and alerting Expected Outcomes By the end of this workshop, you will:\nUnderstand modern serverless data pipeline architectures Master AWS Lambda for data collection and processing Build batch analytics capabilities using real data Implement monitoring and cost optimization Create interactive business dashboards with QuickSight Integrate external APIs into AWS data pipelines Optimize costs with minimal AWS services (under $3/month) Workshop Duration Total Time: 4-6 hours Skill Level: Beginner to Intermediate Cost: Under $3 using AWS Free Tier (simplified architecture) Prerequisites Active AWS account with administrative access Basic understanding of cloud computing concepts Familiarity with JSON data format and REST APIs Internet connection to access DummyJSON API Optional: Basic Python or SQL knowledge Workshop Modules Introduction \u0026amp; Architecture Design Data Collection with Lambda Data Processing and Transformation Setting up S3 Data Lake Analytics with Amazon Athena Visualization with QuickSight Monitoring and Optimization Cleanup and Next Steps "
},
{
	"uri": "//localhost:1313/2-data-collection-lambda/",
	"title": "Data Collection with Lambda",
	"tags": [],
	"description": "",
	"content": "Module Overview In this module, we\u0026rsquo;ll create an AWS Lambda function to collect data from the DummyJSON API. This serverless approach is perfect for our use case since DummyJSON provides static data that doesn\u0026rsquo;t require real-time streaming.\nWhat You\u0026rsquo;ll Learn üîß Create AWS Lambda functions for data collection üìÖ Schedule Lambda execution using CloudWatch Events üåê Integrate with external APIs (DummyJSON) üíæ Store data in S3 for further processing üîç Monitor and troubleshoot Lambda functions Architecture Overview graph TD\rA[DummyJSON API] --\u0026gt; B[Lambda Collector]\rC[CloudWatch Events] --\u0026gt; B\rB --\u0026gt; D[S3 Raw Data]\rE[CloudWatch Logs] --\u0026gt; B Expected Outcomes By the end of this module:\n‚úÖ Lambda function collecting data from DummyJSON ‚úÖ Scheduled execution every 6 hours ‚úÖ Raw data stored in S3 buckets ‚úÖ Proper error handling and logging Let\u0026rsquo;s start building our data collection pipeline!\nEstimated Time: 45-60 minutes to complete this module\n"
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]